{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Objectives:\n",
    "\n",
    "### - Create SQL DBs and populate them using Python\n",
    "\n",
    "### - Interact with SQL DBs using Python and Pandas\n",
    "\n",
    "### - Understand Joins Using SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In order to run SQL scripts from Python we are going to need a few things.\n",
    "#### - SQL Database.\n",
    "#### - Established connection.\n",
    "#### - Familiarity with \"How to SQL.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The sqlite3 package\n",
    "\n",
    "The command line utility can be useful for basic SQL tasks, but since we're using Python for the rest of code it will often be easier to access sqlite directly from within Python. We can use the Python sqlite3 package for just this purpose.\n",
    "\n",
    "Open a connection to an SQLite database file. As before, if the file does not already exist it will automatically be created."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to see your data in SQL DB form you can download a SQLite Manager.\n",
    "\n",
    "You can download a very limited trial version here: http://www.sqlabs.com/sqlitemanager.php\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "# Establishing our Database path.  If no database exists here, this will create one.\n",
    "sqlite_db = 'data/sql/test_db.sqlite'\n",
    "\n",
    "# Establishing the SQL Connection to our Database.  \n",
    "conn = sqlite3.connect(sqlite_db)\n",
    "\n",
    "c = conn.cursor()\n",
    "# Cursor objects allow you to keep track of which result set is which, \n",
    "# since it's possible to run multiple queries before you're done fetching the results of the first.\n",
    "# CURSORS seem to be a tool for iterating over tables row-by-row\n",
    "# This is a conceptual SQL object that is hard to give a very clear consise definition of."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The syntax to create a table is similar to the console, only now we use the execute method of the cursor object c that we just created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We can use the 'execute' function on our Database Connection (With Cursor) to execute a SQL Query.\n",
    "c.execute('CREATE TABLE houses (field1 INTEGER PRIMARY KEY, sqft INTEGER, bdrms INTEGER, age INTEGER, price INTEGER);')\n",
    "\n",
    "# sqlite.connect('data/sql/test_db.sqlite').cursor().execute()\n",
    "\n",
    "# Save (commit) the changes (Just like GitHub)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the database saved the table should now be viewable using SQLite Manager.\n",
    "\n",
    "### Adding data\n",
    "\n",
    "Since we're back in python, we can now use regular programming techniques in conjunction with the sqlite connection. In particular, the cursor's execute() method supports value substitution using the ? character, which makes adding multiple records a bit easier. Check out documentation for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We can create a tuple\n",
    "last_sale = (None, 4000, 5, 22, 619000)\n",
    "\n",
    "# We can insert said tuple into the database table using character substitution.\n",
    "c.execute('INSERT INTO houses VALUES (?, ?, ?, ?, ?)', last_sale)\n",
    "\n",
    "# Remember to commit the changes\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that in this syntax we use the python None value, rather than NULL, to trigger SQLite to auto-increment the Primary Key.\n",
    "\n",
    "There is a related cursor method executemany() which takes an array of tuples and loops through them, substituting one tuple at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We can use the same logic to insert a whole list of tuples!\n",
    "# Tell me thats not helpful!\n",
    "recent_sales = [\n",
    "  (None, 2390, 4, 34, 319000),\n",
    "  (None, 1870, 3, 14, 289000),\n",
    "  (None, 1505, 3, 90, 269000),\n",
    "]\n",
    "\n",
    "c.executemany('INSERT INTO houses VALUES (?, ?, ?, ?, ?)', recent_sales)\n",
    "\n",
    "# c.execute('DELETE FROM houses WHERE rowid > 8')\n",
    "\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, use SQLite Manager to verify the database contents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas and SQL\n",
    "\n",
    "#### Pandas connector\n",
    "\n",
    "While databases provide many analytical capabilities, often it's useful to pull the data back into Python for it's more flexible programming operations. Large, fixed operations would be more efficient in a database, but Pandas allows for interactive processing.\n",
    "\n",
    "For example, if you want to aggregate nightly log-ins or sales to present a report or dashboard, this operation is likely not changing and operating on a large dataset. This can run very efficiently in a database rather than by connecting to it with Python.\n",
    "\n",
    "However, if we want to investigate login or sales data further and ask more interactive questions, then Python would be more practical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas Functions for SQL\n",
    "\n",
    "#### read_sql_table(table_name, con[, schema, ...])\n",
    "    - Read SQL database table into a DataFrame.\n",
    "#### read_sql_query(sql, con[, index_col, ...])\n",
    "    - Read SQL query into a DataFrame.\n",
    "#### read_sql(sql, con[, index_col, ...])\n",
    "    - Read SQL query or database table into a DataFrame.\n",
    "    - a convenience wrapper around read_sql_table() and read_sql_query()\n",
    "    - will delegate to specific function depending on the provided input\n",
    "#### DataFrame.to_sql(name, con[, flavor, ...])\n",
    "    - Write records stored in a DataFrame to a SQL database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Create a SQL DB and tables using Pandas DFs and CSVs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "First we will need to read our CSV files into Python before we can use Python to convert it to a SQL style dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.io import sql\n",
    "\n",
    "cars = pd.read_csv('data/csv/car-names.csv', encoding = 'utf-8')\n",
    "# If you don't specify the type encoding as 'utf-8' you're going to have a bad time when you try to convert to SQL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Checking what our dataframe looks like\n",
    "cars.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Checking for nulls in our data\n",
    "cars.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import Sqlite3 Library\n",
    "import sqlite3\n",
    "\n",
    "# Establishing the Connection to our Database.  If no database exists here, this will create one.\n",
    "connection = sqlite3.connect('data/sql/Cars.db.sqlite')\n",
    "\n",
    "# Keep in mind the directory your notebook is open in is the base directory for all of our SQL actions from here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If you check that directory now you should see an 'Cars.db' sql file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Converts a DataFrame into a SQL database\n",
    "cars.to_sql(name = 'car_names', con = connection, if_exists = 'replace', index = False)\n",
    "\n",
    "# name = name of the database useful if you have multiple tables in a SQL database\n",
    "# con = the connection path to where the data should be placed\n",
    "# if_exists = condition to pass if the database already exists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the below will allow you to acess a database store in memory(RAM) as opposed to in Storage, if you wanted a temporary SQL database\n",
    "\n",
    "``` python\n",
    "conn = sqlite3.connect(':memory:')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating a Table for Order Breakdowns\n",
    "makers = pd.read_csv('data/csv/car-makers.csv', encoding = 'utf-8')\n",
    "\n",
    "connection = sqlite3.connect('data/sql/Cars.db.sqlite')\n",
    "\n",
    "makers.to_sql(name = 'car_makers', con = connection, if_exists = 'replace', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Creating a Table for the Sales Targets\n",
    "data = pd.read_csv('data/csv/cars-data.csv',encoding = 'utf-8')\n",
    "\n",
    "connection = sqlite3.connect('data/sql/Cars.db.sqlite')\n",
    "\n",
    "data.to_sql(name = 'car_data', con = connection, if_exists = 'replace', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# When reading in data to a SQL DB from pandas, how to specify a Key in the table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect to SQL DB and read SQL tables into Pandas DFs\n",
    "#### (Also, return to SQL DataFrames modified tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#The SQL Sub-library from Pandas will allow us to run SQL queries within python.\n",
    "from pandas.io import sql\n",
    "# We already imported sqlite3, but it will also be needed for reading in SQL \n",
    "import sqlite3\n",
    "\n",
    "# Specifying the SQL Path to the SQL Database\n",
    "connection = sqlite3.connect('data/sql/Cars.db.sqlite')\n",
    "\n",
    "# This is our SQL Query\n",
    "query = 'select * from car_names'\n",
    "\n",
    "# Using the read_sql from the Pandas SQL library and setting it equal to a DF object.\n",
    "cars = sql.read_sql(query, con = connection)\n",
    "\n",
    "cars.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Run SQL Queries using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sql.read_sql('select * from car_names', connection).head()\n",
    "\n",
    "#sql = Our SQL query as a string\n",
    "#con = is the connection path to our SQL Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Figure out how to read all the table names in a connection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Review Joins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Normalized and Denormalized Databases\n",
    "\n",
    "There are several ways to organize data in a relational database. Two common definitions for data setups are: normalized and denormalized.\n",
    "\n",
    "__Normalized__ structures have a single table per entity, and use many foreign keys or link tables to connect the entities.\n",
    "\n",
    "__Denormalized__ tables have fewer tables and may (for example) place all of the tweets and the information on users in one table.\n",
    "\n",
    "Each style has advantages and disadvantages. Denormalized tables duplicate a lot of information. For example, in a combined tweets/users table, we may store the address of each user. Now instead of storing this once per user, we are storing this once per tweet!\n",
    "\n",
    "However, this makes the data easy to access if we ever need to find the tweet along with the user's location.\n",
    "\n",
    "Normalized tables save the storage space by separating the information. However, if we ever need to access those two pieces of information, we would need to join the two tables, which can be a fairly slow operation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Join Types\n",
    "\n",
    "SQL joins are used when data is spread in different tables. A join operation allows to combine rows from two or more tables in a single new table. In order for this to be possible, a common field between the tables need to exist.\n",
    "\n",
    "Join operations can be thought of as operations between two sets, where records with the same key are combined and records missing in one set are either discarded or included as NULL values.\n",
    "\n",
    "_CHECK: _\n",
    "- _Where have you encountered a similar functionality in Pandas?_\n",
    "- _Can you make a couple of examples of how you used that Pandas function in the past?_\n",
    "\n",
    "![join types](images/joins.gif)\n",
    "\n",
    "Join Types:\n",
    "- INNER JOIN: Returns all rows when there is at least one match in BOTH tables\n",
    "- LEFT JOIN: Return all rows from the left table, and the matched rows from the right table\n",
    "- RIGHT JOIN: Return all rows from the right table, and the matched rows from the left table\n",
    "- FULL JOIN: Return all rows when there is a match in ONE of the tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL Joins\n",
    "![sql join types](images/sql-joins.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In the case that typing out sql.read_sql() is a little too much,\n",
    "# we'll create a function shortcut.\n",
    "\n",
    "\n",
    "CARS = sqlite3.connect('data/sql/Cars.db.sqlite')\n",
    "\n",
    "\n",
    "def Q(query, db=CARS):\n",
    "    return sql.read_sql(query, db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Q('select * from car_names limit 5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_car = (None, 'Ferrari','The Ferrari')\n",
    "CARS.execute('INSERT INTO car_names VALUES (?, ?, ?)',new_car)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_car = [None, 'Tesla', None]\n",
    "CARS.execute('INSERT INTO car_names VALUES (?, ?, ?)',new_car)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Q('SELECT * FROM car_names WHERE car_names.\"Model\" = \"Tesla\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Q('select * from car_makers limit 5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Q('select * from car_data limit 5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Order ID is our matching feature that we can use to merge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets Checkout all the ways we can merge these.\n",
    "\n",
    "## Inner\n",
    "\n",
    "The most common type of join is: SQL INNER JOIN (simple join). An SQL INNER JOIN returns all rows from multiple tables where the join condition is met. \n",
    "\n",
    "In our example, an INNER JOIN on \"CustomerID\" takes the intersection of the two datasets, excluding the rows for which CustomerID is null in EITHER of the two tables.\n",
    "\n",
    "Essentially, only matching pairs of Order ID's from both Datasets will be taken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inner_join = Q('SELECT car_names.\"Make\", car_data.\"MPG\", car_data.\"Horsepower\", car_data.\"Year\" '\n",
    "'FROM car_names '\n",
    "'INNER JOIN car_data '\n",
    "'ON car_names.\"Id\"=car_data.\"Id\"')\n",
    "inner_join.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inner_join.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Left\n",
    "\n",
    "The LEFT JOIN keyword returns all rows from the left table (table1), with the matching rows in the right table (table2). The result is NULL in the right side when there is no match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "left_join = Q('SELECT car_names.\"Make\", car_data.\"MPG\", car_data.\"Horsepower\", car_data.\"Year\" '\n",
    "'FROM car_names '\n",
    "'LEFT JOIN car_data '\n",
    "'ON car_names.\"Id\"=car_data.\"Id\"')\n",
    "left_join.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "left_join.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Right\n",
    "\n",
    "Similarly, the RIGHT JOIN keyword returns all rows from the right table (table2), with the matching rows in the left table (table1). The result is NULL in the left side when there is no match."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Outer\n",
    "\n",
    "The FULL OUTER JOIN keyword returns all rows from the left table (table1) and from the right table (table2). The FULL OUTER JOIN keyword combines the result of both LEFT and RIGHT joins. In this case we could have NULL values on both sides."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No examples for RIGHT and FULL OUTER because, they are not supported in this relation.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Addtional Resources:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kind of long winded, but a good resource as far as explaining Pandas functions from a SQL programmers perspective.\n",
    "(The opposite situation of us.)\n",
    "\n",
    "Pydata Video:\n",
    "https://www.youtube.com/watch?v=1uVWjdAbgBg\n",
    "\n",
    "Assciated GitHub Repo:\n",
    "https://github.com/gjreda/pydata2014nyc/tree/master/data\n",
    "\n",
    "\n",
    "\n",
    "Pandas Merge, Join and Concatenate\n",
    "http://pandas.pydata.org/pandas-docs/stable/merging.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
