{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LEARNING OBJECTIVES\n",
    "\n",
    "After this lesson, you will be able to:\n",
    "\n",
    "* Use metrics to describe the composition of a cluster\n",
    "* Evaluate the results of a K-Means Clustering Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quick review of K-Means:\n",
    "* Clusters data by trying to separatesamples into n groups of equal variance minimizing inertia\n",
    "* Algorithm requires the number of clusters to be specified\n",
    "\n",
    "The algorithm works like so:  \n",
    "* The first step chooses the initial centroids, with the most basic method being to choose k samples from the dataset X. \n",
    "* After initialization, K-means consists of looping between the two other steps:\n",
    "    * The first step assigns each sample to its nearest centroid. \n",
    "    * The second step creates new centroids by taking the mean value of all of the samples assigned to each previous centroid. The difference between the old and the new centroids are computed and the algorithm repeats these last two steps until this value is less than a threshold. In other words, it repeats until the centroids do not move significantly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To the internets!\n",
    "\n",
    "https://www.naftaliharris.com/blog/visualizing-k-means-clustering/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example above, how do we define what is a \"good\" or \"bad\" cluster?\n",
    "\n",
    "The key to understanding your clustering analysis are the visual evaluation of your clusters, and the computation of metrics that can measure how good your analysis is and how to interpret it. In the following sections, we'll look at a few common methods for understanding and validating your analysis.\n",
    "\n",
    "Our evaluation of the clusters should look at whether the separations of the data are similar to some ground truth set of classes or if they satisfy some assumption such that members belong to the same class are more similar that members of different classes according to some similarity metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization\n",
    "\n",
    "When evaluating clusters, the first and easiest method is to visually examine the output of the clustering algorithm. After we run the algorithm and calculate the centroids as we did in the previous lesson, we can plot the resulting clusters to see where the centroids are based and how the clusters are grouping.\n",
    "\n",
    "<img src = 'assets/plot.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guided Practice: Perform a K-Means Analysis and Evaluate the Clusters\n",
    "\n",
    "K-Means can be used as a supervised, semi-supervised and unsupervised learning technique.  \n",
    "\n",
    "Remember:\n",
    "\n",
    "Classification: \"What is this observation most like?\"\n",
    "\n",
    "Clustering: \"Where can I draw separating boundries that will best help me understand my data?\"  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "import matplotlib.cm as cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here's your prompt:\n",
    "\n",
    "James Cameron went deep, deep, deep sea diving and took a sample of all the fish down there. Unfortunately, James could not 'sea' any of the fish and had to rely on laser measurements (not because it was dark, but because Avatar 2 was so majestic it blinded him for life, like staring into the sun).   \n",
    "\n",
    "He had to go attend some film festival so he left if up to you to determine how many species of fish were observed in the depths of the ocean.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fish = pd.read_csv('assets/data/fish_u.csv')\n",
    "fish.drop('Unnamed: 0',axis =1, inplace = True)\n",
    "fish.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# As an Fishologist you know that the Caudal Fin Length and Pectorial Fin Length are highly predictive of fish species.\n",
    "fish.plot(kind = 'scatter', x ='caudal_fin',y ='pec_fin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There diffinitely appears to be a single class which stands out from the rest of this data.\n",
    "\n",
    "\n",
    "We can draw 3/4 straight lines throught the rest of the data to chop it up into 4 or 5 more groups, or we can leave it as is.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = assets/images/wnb.jpeg>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets run our K-Means with both a K of 2 and a K of 5\n",
    "\n",
    "Step 3: Perform a K-Means test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Perform a K-Means test\n",
    "\n",
    "First, let's define the columns. We're going to using \"quality\" to define class as \"y\" and the rest of our variables as \"x.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# As K Means is an unsupervised, having a Y is not necessary for anything but evaluating.\n",
    "X = fish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k = 2\n",
    "kmeans2 = KMeans(n_clusters=k)\n",
    "kmeans2.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k = 6\n",
    "kmeans6 = KMeans(n_clusters=k)\n",
    "kmeans6.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's get the labels and centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels2 = kmeans2.labels_\n",
    "centroids2 = kmeans2.cluster_centers_\n",
    "\n",
    "labels6 = kmeans6.labels_\n",
    "centroids6 = kmeans6.cluster_centers_\n",
    "# and print the labels to take a look at what our predicted classes are.\n",
    "\n",
    "print labels2\n",
    "print centroids2\n",
    "print # Blank space\n",
    "print labels6\n",
    "print centroids6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These labels and centroids are those after the final iteration. We are used to looking at the centroids in 2 dimensions, but in this example we have 4 features we are compairing, that is why each centroid has 4 coordinates assocaited with it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 4: Evaluate the clusters\n",
    "Lets compute the silhouette scores:\n",
    "\n",
    "\n",
    "What is a silhouette score?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Silhouette Score/Coefficient\n",
    "\n",
    "The silhouette score, or silhouette coefficient, is the measure of how closely related a point is to members of its cluster rather than members of other clusters. If the resulting score is high, then the clustering analysis has an appropriate number of clusters. If the score is low, there are either too many or too few clusters.\n",
    "\n",
    "\n",
    "* The best value is 1 and the worst value is -1\n",
    "* Negative values generally indicate that a sample has been assigned to the wrong cluster, as a different cluster is more similar.\n",
    "\n",
    "Silhouette Algorithm\n",
    "\n",
    "<img src=\"assets/images/silh.png\">  \n",
    "\n",
    "a: The mean distance between an observation and all other points in the same class.  \n",
    "\n",
    "b: The mean distance between an observation and all other points in the next nearest cluster.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "silhouette_score(X, labels2 ,metric='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "silhouette_score(X, labels6 ,metric='euclidean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Ok, but what about the Visualization???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##I took this straight from sklearn\n",
    "range_n_clusters = [2, 6]\n",
    "\n",
    "for n_clusters in range_n_clusters:\n",
    "    # Create a subplot with 1 row and 2 columns\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    fig.set_size_inches(18, 7)\n",
    "\n",
    "    # The 1st subplot is the silhouette plot\n",
    "    # The silhouette coefficient can range from -1, 1 but in this example all\n",
    "    # lie within [-0.1, 1]\n",
    "    ax1.set_xlim([-0.1, 1])\n",
    "    # The (n_clusters+1)*10 is for inserting blank space between silhouette\n",
    "    # plots of individual clusters, to demarcate them clearly.\n",
    "    ax1.set_ylim([0, len(X) + (n_clusters + 1) * 10])\n",
    "\n",
    "    # Initialize the clusterer with n_clusters value and a random generator\n",
    "    # seed of 10 for reproducibility.\n",
    "    clusterer = KMeans(n_clusters=n_clusters, random_state=10)\n",
    "    cluster_labels = clusterer.fit_predict(X)\n",
    "\n",
    "    # The silhouette_score gives the average value for all the samples.\n",
    "    # This gives a perspective into the density and separation of the formed\n",
    "    # clusters\n",
    "    silhouette_avg = silhouette_score(X, cluster_labels)\n",
    "    print(\"For n_clusters =\", n_clusters,\n",
    "          \"The average silhouette_score is :\", silhouette_avg)\n",
    "\n",
    "    # Compute the silhouette scores for each sample\n",
    "    sample_silhouette_values = silhouette_samples(X, cluster_labels)\n",
    "\n",
    "    y_lower = 10\n",
    "    for i in range(n_clusters):\n",
    "        # Aggregate the silhouette scores for samples belonging to\n",
    "        # cluster i, and sort them\n",
    "        ith_cluster_silhouette_values = \\\n",
    "            sample_silhouette_values[cluster_labels == i]\n",
    "\n",
    "        ith_cluster_silhouette_values.sort()\n",
    "\n",
    "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "\n",
    "        color = cm.spectral(float(i) / n_clusters)\n",
    "        ax1.fill_betweenx(np.arange(y_lower, y_upper),\n",
    "                          0, ith_cluster_silhouette_values,\n",
    "                          facecolor=color, edgecolor=color, alpha=0.7)\n",
    "\n",
    "        # Label the silhouette plots with their cluster numbers at the middle\n",
    "        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "\n",
    "        # Compute the new y_lower for next plot\n",
    "        y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "\n",
    "    ax1.set_title(\"The silhouette plot for the various clusters.\")\n",
    "    ax1.set_xlabel(\"The silhouette coefficient values\")\n",
    "    ax1.set_ylabel(\"Cluster label\")\n",
    "\n",
    "    # The vertical line for average silhouette score of all the values\n",
    "    ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "    ax1.set_yticks([])  # Clear the yaxis labels / ticks\n",
    "    ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "\n",
    "    # 2nd Plot showing the actual clusters formed\n",
    "    colors = cm.spectral(cluster_labels.astype(float) / n_clusters)\n",
    "    ax2.scatter(X['caudal_fin'], X['pec_fin'], marker='.', s=50, lw=0, alpha=0.7,\n",
    "                c=colors)\n",
    "\n",
    "    ax2.set_title(\"The visualization of the clustered data.\")\n",
    "    ax2.set_xlabel(\"Feature space for the 1st feature\")\n",
    "    ax2.set_ylabel(\"Feature space for the 2nd feature\")\n",
    "\n",
    "    plt.suptitle((\"Silhouette analysis for KMeans clustering on sample data \"\n",
    "                  \"with n_clusters = %d\" % n_clusters),\n",
    "                 fontsize=14, fontweight='bold')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Might as well create a function to do all values of K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Metric, K values and dataframe to append to\n",
    "from sklearn.metrics import silhouette_score\n",
    "kays = [2,3,4,5,6,7,8,9]\n",
    "results = pd.DataFrame(columns = ['k','silhouette_score'])\n",
    "\n",
    "for k_item in kays:\n",
    "    # Sets model for each K value\n",
    "    kmeans_k = KMeans(n_clusters=k_item)\n",
    "    # fits model\n",
    "    kmeans_k.fit(X)\n",
    "\n",
    "    # Get labels for model evaluation.  Centroids if we want to use those later.\n",
    "    labels_k = kmeans_k.labels_\n",
    "    centroids_k = kmeans_k.cluster_centers_\n",
    "\n",
    "    # Calculates Silhouette score.\n",
    "    s_k = silhouette_score(X, labels_k ,metric='euclidean')\n",
    "    # Appends information to results DF\n",
    "    results.loc[len(results)] = [k_item, s_k]\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Silhouette Score is a useful metric for unsupervised learning, but there is more than one way to skin a cat.\n",
    "Traditional supervised clustering evaluations include, but are not limited too:\n",
    "\n",
    "- Accuracy Score\n",
    "- Confusion Matrix\n",
    "- Classification Reports  \n",
    "\n",
    "Some new ways to skin a clustering cat:  \n",
    "\n",
    "- Completeness Score\n",
    "- Homogeneity\n",
    "- V Measure Score\n",
    "- Mutual Information Score\n",
    "\n",
    "##### Completeness Score- All members of a given class are assigned to the same cluster.\n",
    "\n",
    "* A clustering result satisfies completeness if all the data points that are members of a given class are elements of the same cluster. (If a cluster contains all of the data points of a single class.)\n",
    "* Score between 0.0 and 1.0. 1.0 stands for perfectly complete labeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Homogeneity: each cluster contains only members of a single class.  \n",
    "* A clustering result satisfies homogeneity if all of its clusters contain only data points which are members of a single class. (Every cluster is composed of data points from only 1 class. Essentually there are representative of a class)   \n",
    "\n",
    "* Score between 0.0 and 1.0. 1.0 stands for perfectly homogeneous labeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### V Measure Score\n",
    "\n",
    "The V-measure is the harmonic mean between homogeneity and completeness:  \n",
    "\n",
    "v = 2 * (homogeneity x completeness) / (homogeneity + completeness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To the docs!\n",
    "\n",
    "http://scikit-learn.org/stable/modules/clustering.html#clustering-performance-evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion:\n",
    "\n",
    "* There are numerous methods for evaluating your clustering analysis (how many can you recall?)\n",
    "* After analyzing clusters, you may have to go back and tune the value of \"k\" in your analysis\n",
    "* Always examine multiple metrics to understand how our analysis performed"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
