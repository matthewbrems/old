{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees and Ensembles Lab\n",
    "\n",
    "In this lab we will compare the performance of a simple Decision Tree classifier with a Bagging classifier. We will do that on few datasets, starting from the ones offered by Scikit Learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Breast Cancer Dataset\n",
    "We will start our comparison on the breast cancer dataset.\n",
    "You can load it directly from scikit-learn using the `load_breast_cancer` function.\n",
    "\n",
    "### 1.a Simple comparison\n",
    "1. Load the data and create X and y\n",
    "- Initialize a Decision Tree Classifier and use cross_val_score to evaluate it's performance. Set crossvalidation to 5-folds\n",
    "- Wrap a Bagging Classifier around the Decision Tree Classifier and use cross_val_score to evaluate it's performance. Set crossvalidation to 5-folds. \n",
    "- Which score is better? Are the score significantly different? How can you judge that?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Load the data and create X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pretty much the detail imports \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get that breast Cancer dataset from Sklearn\n",
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the data into a variable\n",
    "data = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['target_names', 'data', 'target', 'DESCR', 'feature_names']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The Data from Sklearn is stored in a dictionary so we can view the keys.\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Converting data into a dataframe structure \n",
    "X = pd.DataFrame(data['data'], columns=data['feature_names'])\n",
    "# Setting up our Y value as well\n",
    "y = pd.Series(data['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension           ...             worst radius  \\\n",
       "0                 0.07871           ...                    25.38   \n",
       "1                 0.05667           ...                    24.99   \n",
       "2                 0.05999           ...                    23.57   \n",
       "3                 0.09744           ...                    14.91   \n",
       "4                 0.05883           ...                    22.54   \n",
       "\n",
       "   worst texture  worst perimeter  worst area  worst smoothness  \\\n",
       "0          17.33           184.60      2019.0            0.1622   \n",
       "1          23.41           158.80      1956.0            0.1238   \n",
       "2          25.53           152.50      1709.0            0.1444   \n",
       "3          26.50            98.87       567.7            0.2098   \n",
       "4          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   worst compactness  worst concavity  worst concave points  worst symmetry  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   worst fractal dimension  \n",
       "0                  0.11890  \n",
       "1                  0.08902  \n",
       "2                  0.08758  \n",
       "3                  0.17300  \n",
       "4                  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# QUick view of the data\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.627417\n",
       "0    0.372583\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the distribution of malignant and benign\n",
    "y.value_counts()/y.count()\n",
    "# Class 1: Benign\n",
    "# Class 2: Malignant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Initialize a Decision Tree Classifier and use cross_val_score to evaluate it's performance. Set crossvalidation to 5-folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lets get to bagging our decision Trees\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.cross_validation import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set the Decision Tree Classifer\n",
    "dt = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.91919969218930342, 0.014955371601639518)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a function to easily do cross validations on different models\n",
    "def do_cross_val(model):\n",
    "    scores = cross_val_score(model, X, y, cv=5, n_jobs=-1)\n",
    "    return scores.mean(), scores.std()\n",
    "\n",
    "do_cross_val(dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Wrap a Bagging Classifier around the Decision Tree Classifier and use cross_val_score to evaluate it's performance. Set crossvalidation to 5-folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bdt = BaggingClassifier(DecisionTreeClassifier())\n",
    "# Remember, you have to put a classifier into the bag first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.94739515198153135, 0.016274615508727188)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "do_cross_val(bdt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Which score is better? Are the score significantly different? How can you judge that?\n",
    "\n",
    "- The bagged model has a score (93.3%) that is slightly higher than the baseline model(91.6%).\n",
    "- The scores standard deviation is very low indicating that the scores from each of the cross validated folds are very similar.  Additionally, the standard deviation of both models is almost the same; 0.0128 and 0.0129.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.b Scaled pipelines\n",
    "As you may have noticed the features are not normalized. Do the score improve with normalization?\n",
    "By now you should be very familiar with pipelines and scaling, so:\n",
    "\n",
    "1. Create 2 pipelines, with a scaling preprocessing step and then either a decision tree or a bagging decision tree.\n",
    "- Which score is better? Are the score significantly different? How can you judge that?\n",
    "- Are the scores different from the non-scaled data?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Create 2 pipelines, with a scaling preprocessing step and then either a decision tree or a bagging decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pipeline for just a decision tree with a robust scaler.\n",
    "# You can use whatever scaler you like.\n",
    "pipedt = make_pipeline(RobustScaler(),\n",
    "                       DecisionTreeClassifier())\n",
    "\n",
    "pipebdt = make_pipeline(RobustScaler(),\n",
    "                        BaggingClassifier(DecisionTreeClassifier()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Robust scaling is a scaling method that takes into consideration the median and the interquartile range so it is an effective scaling technique when dealing with normally distributed data that contains outliers.  \n",
    "\n",
    "(I don't have a better definition because I could not find a reasonable formula for it.  I put it in here more or less to introduce you to another scaling method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Which score is better? Are the score significantly different? How can you judge that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.91919969218930342, 0.014955371601639518)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "do_cross_val(pipedt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.94739515198153135, 0.016274615508727188)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "do_cross_val(pipebdt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Even though the information has been scaled, the results are identical to the unscaled. This is probably a good indication that our data is either unaffected by scaling or the scaling method used is not useful.\n",
    "- Just like in our previous answer, the scores have very low standard deviations indication there is no significant difference between the results of our cross validation folds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Are the scores different from the non-scaled data?\n",
    "- No, Scores are the exact same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.c Grid Search\n",
    "\n",
    "Grid search is a great way to improve the performance of a classifier. Let's explore the parameter space of both models and see if we can improve their performance.\n",
    "\n",
    "1. Initialize a GridSearchCV with 5-fold cross validation for the Decision Tree Classifier\n",
    "- Search for few values of the parameters in order to improve the score of the classifier\n",
    "- Use the whole X, y dataset for your test\n",
    "- Check the best\\_score\\_ once you've trained it. Is it better than before?\n",
    "- how does the score of the Grid-searched DT compare with the score of the Bagging DT?\n",
    "\n",
    "- Initialize a GridSearchCV with 5-fold cross validation for the Bagging Decision Tree Classifier\n",
    "- Repeat the search\n",
    "    - Note that you'll have to change parameter names for the base_estimator\n",
    "    - Note that there are also additional parameters to change\n",
    "    - Note that you may end up with a grid space to large to search in a short time\n",
    "    - Make use of the n_jobs parameter to speed up your grid search\n",
    "\n",
    "- Does the score improve for the Grid-searched Bagging Classifier?\n",
    "> Yes\n",
    "- Which score is better? Are the score significantly different? How can you judge that?\n",
    "> The grid search bagging classifier is the best one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Initialize a GridSearchCV with 5-fold cross validation for the Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Search for few values of the parameters in order to improve the score of the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Be careful when setting gridsearch params as some of them can step on \n",
    "# eachothers toes with the Decision Tree.  \n",
    "params = {\"max_depth\": [3,5,10,20],\n",
    "          \"max_features\": [None, \"auto\"],\n",
    "          \"min_samples_leaf\": [1, 3, 5, 7, 10],\n",
    "          \"min_samples_split\": [2, 5, 7]\n",
    "         }\n",
    "    \n",
    "\n",
    "gsdt = GridSearchCV(dt, params, n_jobs=-1, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Use the whole X, y dataset for your test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best'),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'max_features': [None, 'auto'], 'min_samples_split': [2, 5, 7], 'max_depth': [3, 5, 10, 20], 'min_samples_leaf': [1, 3, 5, 7, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Surpisingly does not take too long\n",
    "gsdt.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 5,\n",
       " 'max_features': 'auto',\n",
       " 'min_samples_leaf': 5,\n",
       " 'min_samples_split': 5}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsdt.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Check the best\\_score\\_ once you've trained it. Is it better than before?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95079086115992972"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsdt.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It did improve!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             presort=False, random_state=None, splitter='best'),\n",
       " 'base_estimator__class_weight': None,\n",
       " 'base_estimator__criterion': 'gini',\n",
       " 'base_estimator__max_depth': None,\n",
       " 'base_estimator__max_features': None,\n",
       " 'base_estimator__max_leaf_nodes': None,\n",
       " 'base_estimator__min_samples_leaf': 1,\n",
       " 'base_estimator__min_samples_split': 2,\n",
       " 'base_estimator__min_weight_fraction_leaf': 0.0,\n",
       " 'base_estimator__presort': False,\n",
       " 'base_estimator__random_state': None,\n",
       " 'base_estimator__splitter': 'best',\n",
       " 'bootstrap': True,\n",
       " 'bootstrap_features': False,\n",
       " 'max_features': 1.0,\n",
       " 'max_samples': 1.0,\n",
       " 'n_estimators': 10,\n",
       " 'n_jobs': 1,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bdt.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. how does the score of the Grid-searched DT compare with the score of the Bagging DT?\n",
    "\n",
    "- It is better by about 1 percent.  Which is pretty significant once you get above 90%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Initialize a GridSearchCV with 5-fold cross validation for the Bagging Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# One more time, more features and bootstrapped\n",
    "params = {\"base_estimator__max_depth\": [3,5,10,20],\n",
    "          \"base_estimator__max_features\": [None, \"auto\"],\n",
    "          \"base_estimator__min_samples_leaf\": [1, 3, 5, 7, 10],\n",
    "          \"base_estimator__min_samples_split\": [2, 5, 7],\n",
    "          'bootstrap_features': [False, True],\n",
    "          'max_features': [0.5, 0.7, 1.0],\n",
    "          'max_samples': [0.5, 0.7, 1.0],\n",
    "          'n_estimators': [2, 5, 10, 20],\n",
    "         }\n",
    "    \n",
    "\n",
    "gsbdt = GridSearchCV(bdt, params, n_jobs=-1, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Repeat the search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-cfb8a4f9167c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# This took a really long time to run.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgsbdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# Like, I made a grilled cheese and ate it before this was over.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# 10-20 mins\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m         \"\"\"\n\u001b[0;32m--> 804\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    805\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, parameter_iterable)\u001b[0m\n\u001b[1;32m    551\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m                                     error_score=self.error_score)\n\u001b[0;32m--> 553\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m                 for train, test in cv)\n\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    808\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m                     \u001b[0;31m# a working pool as they expect.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# This took a really long time to run.  \n",
    "gsbdt.fit(X, y)\n",
    "# Like, I made a grilled cheese and ate it before this was over.\n",
    "# 10-20 mins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A really long time to gridsearch is why we want to run gridsearch towards the end of our modelling phases, once we have a better understanding of our data and useful parameters so we are not testing parameters that are somewhat useless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'best_params_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-c55bf3a7193c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgsbdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'best_params_'"
     ]
    }
   ],
   "source": [
    "gsbdt.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.  Does the score improve for the Grid-searched Bagging Regressor?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# But that accuracy score...\n",
    "gsbdt.best_score_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.  Which score is better? Are the score significantly different? How can you judge that?\n",
    "\n",
    "- An accuracy score of 97% is really good, however that is just the best score and so if would be important to consider the standard deviation os scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Diabetes and Regression\n",
    "\n",
    "Scikit Learn has a dataset of diabetic patients obtained from this study:\n",
    "\n",
    "http://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\n",
    "http://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf\n",
    "\n",
    "442 diabetes patients were measured on 10 baseline variables: age, sex, body mass index, average blood pressure, and six blood serum measurements.\n",
    "\n",
    "The target is a quantitative measure of disease progression one year after baseline.\n",
    "\n",
    "Repeat the above comparison between a DecisionTreeRegressor and a Bagging version of the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.a Simple comparison\n",
    "1. Load the data and create X and y\n",
    "- Initialize a Decision Tree Regressor and use cross_val_score to evaluate it's performance. Set crossvalidation to 5-folds. Which score will you use?\n",
    "\n",
    "- Wrap a Bagging Regressor around the Decision Tree Regressor and use cross_val_score to evaluate it's performance. Set crossvalidation to 5-folds. \n",
    "- Which score is better? Are the score significantly different? How can you judge that?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Load the data and create X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "data = load_diabetes()\n",
    "X = data['data']\n",
    "y = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({25.0: 1,\n",
       "         31.0: 1,\n",
       "         37.0: 1,\n",
       "         39.0: 2,\n",
       "         40.0: 1,\n",
       "         42.0: 3,\n",
       "         43.0: 1,\n",
       "         44.0: 1,\n",
       "         45.0: 1,\n",
       "         47.0: 2,\n",
       "         48.0: 3,\n",
       "         49.0: 3,\n",
       "         50.0: 1,\n",
       "         51.0: 3,\n",
       "         52.0: 4,\n",
       "         53.0: 4,\n",
       "         54.0: 1,\n",
       "         55.0: 4,\n",
       "         57.0: 1,\n",
       "         58.0: 1,\n",
       "         59.0: 4,\n",
       "         60.0: 3,\n",
       "         61.0: 2,\n",
       "         63.0: 4,\n",
       "         64.0: 3,\n",
       "         65.0: 4,\n",
       "         66.0: 2,\n",
       "         67.0: 2,\n",
       "         68.0: 3,\n",
       "         69.0: 3,\n",
       "         70.0: 2,\n",
       "         71.0: 5,\n",
       "         72.0: 6,\n",
       "         73.0: 1,\n",
       "         74.0: 2,\n",
       "         75.0: 2,\n",
       "         77.0: 4,\n",
       "         78.0: 3,\n",
       "         79.0: 1,\n",
       "         80.0: 1,\n",
       "         81.0: 2,\n",
       "         83.0: 3,\n",
       "         84.0: 4,\n",
       "         85.0: 4,\n",
       "         86.0: 1,\n",
       "         87.0: 2,\n",
       "         88.0: 4,\n",
       "         89.0: 2,\n",
       "         90.0: 5,\n",
       "         91.0: 4,\n",
       "         92.0: 2,\n",
       "         93.0: 2,\n",
       "         94.0: 3,\n",
       "         95.0: 2,\n",
       "         96.0: 4,\n",
       "         97.0: 4,\n",
       "         98.0: 1,\n",
       "         99.0: 2,\n",
       "         100.0: 1,\n",
       "         101.0: 3,\n",
       "         102.0: 3,\n",
       "         103.0: 2,\n",
       "         104.0: 4,\n",
       "         107.0: 2,\n",
       "         108.0: 1,\n",
       "         109.0: 4,\n",
       "         110.0: 2,\n",
       "         111.0: 3,\n",
       "         113.0: 3,\n",
       "         114.0: 1,\n",
       "         115.0: 2,\n",
       "         116.0: 2,\n",
       "         118.0: 3,\n",
       "         120.0: 1,\n",
       "         121.0: 2,\n",
       "         122.0: 2,\n",
       "         123.0: 1,\n",
       "         124.0: 2,\n",
       "         125.0: 1,\n",
       "         126.0: 1,\n",
       "         127.0: 2,\n",
       "         128.0: 4,\n",
       "         129.0: 3,\n",
       "         131.0: 4,\n",
       "         132.0: 2,\n",
       "         134.0: 2,\n",
       "         135.0: 2,\n",
       "         136.0: 1,\n",
       "         137.0: 2,\n",
       "         138.0: 2,\n",
       "         139.0: 2,\n",
       "         140.0: 2,\n",
       "         141.0: 3,\n",
       "         142.0: 4,\n",
       "         143.0: 2,\n",
       "         144.0: 4,\n",
       "         145.0: 1,\n",
       "         146.0: 1,\n",
       "         147.0: 1,\n",
       "         148.0: 1,\n",
       "         150.0: 4,\n",
       "         151.0: 3,\n",
       "         152.0: 2,\n",
       "         153.0: 1,\n",
       "         154.0: 1,\n",
       "         155.0: 2,\n",
       "         156.0: 1,\n",
       "         158.0: 2,\n",
       "         160.0: 2,\n",
       "         161.0: 1,\n",
       "         162.0: 1,\n",
       "         163.0: 2,\n",
       "         164.0: 2,\n",
       "         166.0: 1,\n",
       "         167.0: 1,\n",
       "         168.0: 3,\n",
       "         170.0: 3,\n",
       "         171.0: 1,\n",
       "         172.0: 2,\n",
       "         173.0: 2,\n",
       "         174.0: 2,\n",
       "         175.0: 1,\n",
       "         177.0: 1,\n",
       "         178.0: 5,\n",
       "         179.0: 2,\n",
       "         180.0: 2,\n",
       "         181.0: 2,\n",
       "         182.0: 3,\n",
       "         183.0: 1,\n",
       "         184.0: 1,\n",
       "         185.0: 3,\n",
       "         186.0: 1,\n",
       "         187.0: 1,\n",
       "         189.0: 1,\n",
       "         190.0: 2,\n",
       "         191.0: 2,\n",
       "         192.0: 1,\n",
       "         195.0: 1,\n",
       "         196.0: 2,\n",
       "         197.0: 2,\n",
       "         198.0: 3,\n",
       "         199.0: 1,\n",
       "         200.0: 6,\n",
       "         201.0: 1,\n",
       "         202.0: 4,\n",
       "         206.0: 2,\n",
       "         208.0: 1,\n",
       "         209.0: 1,\n",
       "         210.0: 1,\n",
       "         212.0: 1,\n",
       "         214.0: 3,\n",
       "         215.0: 1,\n",
       "         216.0: 1,\n",
       "         217.0: 2,\n",
       "         219.0: 2,\n",
       "         220.0: 4,\n",
       "         221.0: 1,\n",
       "         222.0: 1,\n",
       "         225.0: 2,\n",
       "         229.0: 1,\n",
       "         230.0: 2,\n",
       "         232.0: 2,\n",
       "         233.0: 3,\n",
       "         235.0: 2,\n",
       "         236.0: 1,\n",
       "         237.0: 2,\n",
       "         241.0: 1,\n",
       "         242.0: 3,\n",
       "         243.0: 2,\n",
       "         244.0: 1,\n",
       "         245.0: 2,\n",
       "         246.0: 2,\n",
       "         248.0: 3,\n",
       "         249.0: 1,\n",
       "         252.0: 3,\n",
       "         253.0: 1,\n",
       "         257.0: 2,\n",
       "         258.0: 3,\n",
       "         259.0: 3,\n",
       "         261.0: 1,\n",
       "         262.0: 2,\n",
       "         263.0: 2,\n",
       "         264.0: 1,\n",
       "         265.0: 3,\n",
       "         268.0: 2,\n",
       "         270.0: 2,\n",
       "         272.0: 2,\n",
       "         273.0: 1,\n",
       "         274.0: 1,\n",
       "         275.0: 4,\n",
       "         276.0: 1,\n",
       "         277.0: 2,\n",
       "         279.0: 1,\n",
       "         280.0: 1,\n",
       "         281.0: 4,\n",
       "         283.0: 2,\n",
       "         288.0: 1,\n",
       "         292.0: 2,\n",
       "         293.0: 1,\n",
       "         295.0: 1,\n",
       "         296.0: 1,\n",
       "         297.0: 1,\n",
       "         302.0: 1,\n",
       "         303.0: 1,\n",
       "         306.0: 1,\n",
       "         308.0: 1,\n",
       "         310.0: 3,\n",
       "         311.0: 1,\n",
       "         317.0: 1,\n",
       "         321.0: 1,\n",
       "         332.0: 1,\n",
       "         336.0: 1,\n",
       "         341.0: 1,\n",
       "         346.0: 1})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections \n",
    "collections.Counter(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a lot of different target variables. The greatest appearing 6 times in our target data (200). I we predicted Y as 200 for every value our models base score would be 0.01357.  It is a pretty low bar to beat to create a useful model.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Initialize a Decision Tree Regressor and use cross_val_score to evaluate it's performance. Set crossvalidation to 5-folds. Which score will you use?\n",
    "\n",
    "-  I Used an r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "def do_cross_val(model):\n",
    "    scores = cross_val_score(model, X, y, cv=5, n_jobs=-1, scoring='r2')\n",
    "    return scores.mean(), scores.std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.11437863045387864, 0.12602191112786265)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtr = DecisionTreeRegressor()\n",
    "do_cross_val(dtr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Wrap a Bagging Regressor around the Decision Tree Regressor and use cross_val_score to evaluate it's performance. Set crossvalidation to 5-folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.33561365300123336, 0.054215295215910203)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bdtr = BaggingRegressor(DecisionTreeRegressor())\n",
    "do_cross_val(bdtr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Which score is better? Are the score significantly different? How can you judge that?\n",
    "\n",
    "> The Bagging Regressor is better.  That r2 of the baseline decision tree is really bad.\n",
    "> Additionally the standard deviation of the scores from the cross_val_score output. While the Bagged DT did not have a great std dev of score it was a significant improvement from the baseline DT's std dev."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.b Grid Search\n",
    "\n",
    "Repeat Grid search as above:\n",
    "\n",
    "1. Initialize a GridSearchCV with 5-fold cross validation for the Decision Tree Regressor\n",
    "- Search for few values of the parameters in order to improve the score of the regressor\n",
    "- Use the whole X, y dataset for your test\n",
    "- Check the best\\_score\\_ once you've trained it. Is it better than before?\n",
    "- how does the score of the Grid-searched DT compare with the score of the Bagging DT?\n",
    "> Answer: they are the same (within error), Grid search improved the score of simple DT\n",
    "- Initialize a GridSearchCV with 5-fold cross validation for the Bagging Decision Tree Regressor\n",
    "- Repeat the search\n",
    "    - Note that you'll have to change parameter names for the base_estimator\n",
    "    - Note that there are also additional parameters to change\n",
    "    - Note that you may end up with a grid space to large to search in a short time\n",
    "    - Make use of the n_jobs parameter to speed up your grid search\n",
    "\n",
    "- Does the score improve for the Grid-searched Bagging Regressor?\n",
    "> Yes\n",
    "- Which score is better? Are the score significantly different? How can you judge that?\n",
    "> The grid search bagging classifier is the best one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Initialize a GridSearchCV with 5-fold cross validation for the Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtr = DecisionTreeRegressor()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Search for few values of the parameters in order to improve the score of the regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = {\"splitter\": ['best', 'random'],\n",
    "          \"max_depth\": [3,5,10,20],\n",
    "          \"max_features\": [None, \"auto\"],\n",
    "          \"min_samples_leaf\": [1, 3, 5, 7, 10],\n",
    "          \"min_samples_split\": [2, 5, 7]\n",
    "         }\n",
    "    \n",
    "\n",
    "gsdtr = GridSearchCV(dtr, params, n_jobs=-1, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Use the whole X, y dataset for your test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "           splitter='best'),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'max_features': [None, 'auto'], 'splitter': ['best', 'random'], 'min_samples_split': [2, 5, 7], 'max_depth': [3, 5, 10, 20], 'min_samples_leaf': [1, 3, 5, 7, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsdtr.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 20,\n",
       " 'max_features': 'auto',\n",
       " 'min_samples_leaf': 10,\n",
       " 'min_samples_split': 2,\n",
       " 'splitter': 'random'}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsdtr.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Check the best_score_ once you've trained it. Is it better than before?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38995337926147983"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsdtr.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'd say its better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. how does the score of the Grid-searched DT compare with the score of the Bagging DT?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best score from the GridSearch DT is about 3 points higher than the average Bagging DT, however given that the mean from the Bagging DT was .35 and the standard deviation was 0.05 it is possible that the Bagging DT scored as high as 0.40+ which would put it above the predictability of the GridSearched DT.\n",
    "\n",
    "Might as well combined the two and see what happens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Initialize a GridSearchCV with 5-fold cross validation for the Bagging Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = {\"base_estimator__splitter\": ['best', 'random'],\n",
    "          \"base_estimator__max_depth\": [3,5,10,20],\n",
    "          \"base_estimator__max_features\": [None, \"auto\"],\n",
    "          \"base_estimator__min_samples_leaf\": [1, 3, 5, 7, 10],\n",
    "          \"base_estimator__min_samples_split\": [2, 5, 7],\n",
    "          'bootstrap_features': [False, True],\n",
    "          'max_features': [0.5, 0.7, 1.0],\n",
    "          'max_samples': [0.5, 0.7, 1.0],\n",
    "          'n_estimators': [2, 5, 10, 20],\n",
    "         }\n",
    "    \n",
    "\n",
    "gsbdtr = GridSearchCV(bdtr, params, n_jobs=-1, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Repeat the search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=BaggingRegressor(base_estimator=DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "           splitter='best'),\n",
       "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "         max_samples=1.0, n_estimators=10, n_jobs=1, oob_score=False,\n",
       "         random_state=None, verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'n_estimators': [2, 5, 10, 20], 'max_samples': [0.5, 0.7, 1.0], 'base_estimator__min_samples_split': [2, 5, 7], 'base_estimator__max_depth': [3, 5, 10, 20], 'bootstrap_features': [False, True], 'base_estimator__splitter': ['best', 'random'], 'max_features': [0.5, 0.7, 1.0], 'base_estimator__min_samples_leaf': [1, 3, 5, 7, 10], 'base_estimator__max_features': [None, 'auto']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsbdtr.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base_estimator__max_depth': 10,\n",
       " 'base_estimator__max_features': 'auto',\n",
       " 'base_estimator__min_samples_leaf': 7,\n",
       " 'base_estimator__min_samples_split': 5,\n",
       " 'base_estimator__splitter': 'random',\n",
       " 'bootstrap_features': False,\n",
       " 'max_features': 1.0,\n",
       " 'max_samples': 1.0,\n",
       " 'n_estimators': 5}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsbdtr.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Does the score improve for the Grid-searched Bagging Regressor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48609184780132547"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsbdtr.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Which score is better? Are the score significantly different? How can you judge that?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "this one, better score by 10%, but it is a still relatively low score.  What is more important to us is probably how this last model is looking at the data so we can find distinguishing features and values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions:\n",
    "#### Can you use Criterion in a Gridsearch?\n",
    "> Yes, However Gini vs. Entropy only applies to Decision Tree Classifiers.  Decision Tree Regressors take erros measures as their Criterion like MSE and RMSE. \n",
    "\n",
    "#### How to bagg a list of models.\n",
    "> There is no logical reason to oppose the use of multiple different classifiers in an ensemble model. However, Sklearns bagging classifier will only accept a single classifier type.  Combining different classifiers to come to a aggregate conclussion can be reffered to as \"Stacking\"\n",
    "\n",
    "#### Cross Validation, does it just fit one model and test agianst many information sets.\n",
    "> Cross Validation is a model evaluation/validation technique. Ensembling is a model building/tuning technique.  We must keep in mind that Ensembles are in themselves models, like a team of models working together as one. We are not accessing the performance of each of the models, but more or less using them.  One of the most important features of an Ensemble is the ability to randomly select features which does not occur in a CV.  \n",
    "> A cross validation can be used with a Fit or Unfit model and is a way of using different folds(data subsets) to assess how well your model handles variance and/or bias (bias if it is fitting on different folds). \n",
    "\n",
    "#### Is it possible to create a model where the output is two independent features/Predictions.\n",
    "> While it is possible to use the same dataset with multiple y values it does not seem feasable to create a single model whose output is 2 separate predictive values because the model is based off a single algorithm and the coefficients have been weighted according to one prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
