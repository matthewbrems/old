---
title: Train, test split and cross validation
duration: "1:30"
creator:
    name: Joseph Nelson
    city: DC
---

# ![logo](https://ga-dash.s3.amazonaws.com/production/assets/logo-9f88ae6c9c3871690e33280fcf557f33.png) Train, Test Split + Cross Validation

# Learning Objectives

By the end of this lesson, students will: 

- Explain problems associated with over and underfitting
- Grasp why train, test split is necessary 
- Explore kfolds, LOOCV, and three split methods

![train-test-split](./Train-Test-Split-CV.png)

## Additional Resources

- Examine this [academic paper](http://frostiebek.free.fr/docs/Machine%20Learning/validation-1.pdf) on the underpinnings of the holdout method, LOOVC, and kfolds
- The sklearn [documentation](http://scikit-learn.org/stable/modules/cross_validation.html#cross-validation) on cross validation is strong
- This [Stanford lesson](https://www.youtube.com/watch?v=_2ij6eaaSl0) on cross validation
- This [blog post](http://www.win-vector.com/blog/2015/01/random-testtrain-split-is-not-always-enough/) on why TTS is not always enough
- StackExchange [discussion](http://stackoverflow.com/questions/13610074/is-there-a-rule-of-thumb-for-how-to-divide-a-dataset-into-training-and-validatio) on approximate TTS, validation set sizes