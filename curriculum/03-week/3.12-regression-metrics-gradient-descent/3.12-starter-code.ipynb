{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## These gradient descent functions are taken from DSI-2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## This function is designed to take as inputs:\n",
    "##### true (observed) values of Y,\n",
    "##### a vector of inputs (X), \n",
    "##### the estimated y-intercept (beta0),\n",
    "##### and the estimated slope (beta1).\n",
    "\n",
    "## This function is designed to output:\n",
    "##### the mean squared error.\n",
    "\n",
    "def mean_squared_error(y_true, x, beta0, beta1):\n",
    "    y_pred = beta0 + x * beta1\n",
    "    mean_sq_err = np.mean((y_true - y_pred)**2)\n",
    "    return mean_sq_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## This function will iterate through every observed Y and calculate\n",
    "## the gradient for beta0 and for beta1 after \n",
    "\n",
    "## This function is designed to take as inputs:\n",
    "##### observed Y values,\n",
    "##### observed X values,\n",
    "##### an initial guess for beta0,\n",
    "##### an initial guess for beta1,\n",
    "##### and the step size (alpha).\n",
    "\n",
    "## This function is designed to output:\n",
    "##### the updated beta0 and beta1 after ONE iteration of gradient descent.\n",
    "\n",
    "def gradient_update(y, x, beta0, beta1, step_size):\n",
    "\n",
    "    beta0_gradient = 0 # set gradient to 0 to start\n",
    "    beta1_gradient = 0 # set gradient to 0 to start\n",
    "    \n",
    "    N = float(len(y)) # N = number of observations\n",
    "    \n",
    "    for i in range(len(y)):\n",
    "    \n",
    "        beta0_gradient += (2./N * -1 * (y[i] - (beta0 + beta1*x[i])))\n",
    "            # beta0_gradient calculates gradient of beta0 based \n",
    "            # on observed data; calculation derived with calculus\n",
    "            \n",
    "        beta1_gradient += (2./N * -1 * x[i] * (y[i] - (beta0 + beta1*x[i])))\n",
    "            # beta1_gradient calculates gradient of beta1 based \n",
    "            # on observed data; calculation derived with calculus\n",
    "        \n",
    "    beta0 = beta0 - (step_size * beta0_gradient) ## applying gradient descent\n",
    "    beta1 = beta1 - (step_size * beta1_gradient) ## applying gradient descent\n",
    "    \n",
    "    return [beta0, beta1]\n",
    "\n",
    "## Recall: this updates gradient descent ONCE, i.e. going from\n",
    "## initial guess to next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## This function will implement the gradient descent function (i.e. update beta0, beta1 once) over \n",
    "## multiple iterations (in this case, 500).\n",
    "\n",
    "def gradient_descent_iterator(y, x, beta0, beta1, step_size=.0001, iterations=500):\n",
    "    \n",
    "    mean_squared_errors = []\n",
    "    mean_squared_errors.append(mean_squared_error(y, x, beta0, beta1)) \n",
    "        # calculate MSE given observed Y, X, guessed beta0, guessed beta1, add to mean_squared_error list.\n",
    "    \n",
    "    beta0s = [beta0]\n",
    "    beta1s = [beta1]\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        [beta0, beta1] = gradient_update(y, x, beta0, beta1, step_size)\n",
    "            # take in old beta0, old beta1 and output new beta0, beta1\n",
    "        mean_squared_errors.append(mean_squared_error(y, x, beta0, beta1))\n",
    "            # calculate MSE given observed Y, X, \n",
    "        beta0s.append(beta0)\n",
    "            # add new beta0 value to beta0s\n",
    "        beta1s.append(beta1)\n",
    "            # add new beta1 value to beta1s\n",
    "        \n",
    "    return [mean_squared_errors, beta0s, beta1s]\n",
    "        # returns the list of MSE, beta0, and beta1 so that you can (hopefully!) \n",
    "        # see the MSE decrease "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py27]",
   "language": "python",
   "name": "conda-env-py27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
