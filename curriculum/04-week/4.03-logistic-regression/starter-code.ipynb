{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression in Statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.formula.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed_acidity</th>\n",
       "      <th>volatile_acidity</th>\n",
       "      <th>citric_acid</th>\n",
       "      <th>residual_sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free_sulfur_dioxide</th>\n",
       "      <th>total_sulfur_dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>color</th>\n",
       "      <th>is_red</th>\n",
       "      <th>high_quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>red</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>red</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>red</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "      <td>red</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>red</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed_acidity  volatile_acidity  citric_acid  residual_sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free_sulfur_dioxide  total_sulfur_dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality color  is_red  high_quality  \n",
       "0      9.4        5   red     1.0           0.0  \n",
       "1      9.8        5   red     1.0           0.0  \n",
       "2      9.8        5   red     1.0           0.0  \n",
       "3      9.8        6   red     1.0           0.0  \n",
       "4      9.4        5   red     1.0           0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load in the dataset\n",
    "df = pd.read_csv(\"https://s3.amazonaws.com/demo-datasets/wine.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below, we fit a logistic regression model using statsmodels (patsy's) logistic regression formula\n",
    "\n",
    "The formula says that the high_quality (coded as 1 or 0) DEPENDS on (~) following attributes:\n",
    " `residual_sugar, pH, and alcohol`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.418431\n",
      "         Iterations 6\n"
     ]
    }
   ],
   "source": [
    "model = sm.logit(\n",
    "    \"high_quality ~ residual_sugar + pH + alcohol\",\n",
    "    data = df\n",
    ").fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>   <td>high_quality</td>   <th>  No. Observations:  </th>   <td>  6497</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>   <td>  6493</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>   <td>     3</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Mon, 27 Mar 2017</td> <th>  Pseudo R-squ.:     </th>   <td>0.1557</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>15:27:39</td>     <th>  Log-Likelihood:    </th>  <td> -2718.5</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th>  <td> -3219.8</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>5.039e-217</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "         <td></td>           <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>      <td>  -11.7871</td> <td>    0.803</td> <td>  -14.674</td> <td> 0.000</td> <td>  -13.361   -10.213</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>residual_sugar</th> <td>    0.0471</td> <td>    0.009</td> <td>    5.441</td> <td> 0.000</td> <td>    0.030     0.064</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pH</th>             <td>    0.1419</td> <td>    0.217</td> <td>    0.654</td> <td> 0.513</td> <td>   -0.283     0.567</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>alcohol</th>        <td>    0.8946</td> <td>    0.031</td> <td>   28.600</td> <td> 0.000</td> <td>    0.833     0.956</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:           high_quality   No. Observations:                 6497\n",
       "Model:                          Logit   Df Residuals:                     6493\n",
       "Method:                           MLE   Df Model:                            3\n",
       "Date:                Mon, 27 Mar 2017   Pseudo R-squ.:                  0.1557\n",
       "Time:                        15:27:39   Log-Likelihood:                -2718.5\n",
       "converged:                       True   LL-Null:                       -3219.8\n",
       "                                        LLR p-value:                5.039e-217\n",
       "==================================================================================\n",
       "                     coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
       "----------------------------------------------------------------------------------\n",
       "Intercept        -11.7871      0.803    -14.674      0.000       -13.361   -10.213\n",
       "residual_sugar     0.0471      0.009      5.441      0.000         0.030     0.064\n",
       "pH                 0.1419      0.217      0.654      0.513        -0.283     0.567\n",
       "alcohol            0.8946      0.031     28.600      0.000         0.833     0.956\n",
       "==================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.718281828459045"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.exp(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4463570509072867"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.exp(0.8946) ## <-- this is e ^ 0.8946\n",
    "\n",
    "## As alcohol increases by 1 unit, we expect that a wine is\n",
    "## 2.446 times *AS* likely to be classified as \"high-quality.\"\n",
    "## This is the ODDS RATIO associating quality of wine to\n",
    "## alcohol content.\n",
    "\n",
    "## e ^ 0.8946 is the ODDS RATIO\n",
    "## 0.8946 is the LOG-ODDS RATIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the table above\n",
    "- `coef`, represents the coefficients we have learned for each feature\n",
    "        For example, '0.8946' for alcohol represent the change in log odds \n",
    "        As alcohol content increases, the likelihood of high_quality increases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can add interaction effects as well\n",
    "- The `:` operator in patsy / formula-syntax represents when we care about two variables occurring together\n",
    "- The `*` operator expands as follows: `a * b` expands to `a + b + a:b`, both of the original terms and interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.416779\n",
      "         Iterations 6\n"
     ]
    }
   ],
   "source": [
    "model = sm.logit(\n",
    "    \"high_quality ~ residual_sugar * alcohol\",\n",
    "    data = df\n",
    ").fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>   <td>high_quality</td>   <th>  No. Observations:  </th>   <td>  6497</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>   <td>  6493</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>   <td>     3</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Mon, 27 Mar 2017</td> <th>  Pseudo R-squ.:     </th>   <td>0.1590</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>15:42:00</td>     <th>  Log-Likelihood:    </th>  <td> -2707.8</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th>  <td> -3219.8</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>1.109e-221</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "             <td></td>               <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>              <td>  -13.0762</td> <td>    0.532</td> <td>  -24.600</td> <td> 0.000</td> <td>  -14.118   -12.034</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>residual_sugar</th>         <td>    0.3601</td> <td>    0.066</td> <td>    5.431</td> <td> 0.000</td> <td>    0.230     0.490</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>alcohol</th>                <td>    1.0565</td> <td>    0.047</td> <td>   22.343</td> <td> 0.000</td> <td>    0.964     1.149</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>residual_sugar:alcohol</th> <td>   -0.0302</td> <td>    0.006</td> <td>   -4.763</td> <td> 0.000</td> <td>   -0.043    -0.018</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:           high_quality   No. Observations:                 6497\n",
       "Model:                          Logit   Df Residuals:                     6493\n",
       "Method:                           MLE   Df Model:                            3\n",
       "Date:                Mon, 27 Mar 2017   Pseudo R-squ.:                  0.1590\n",
       "Time:                        15:42:00   Log-Likelihood:                -2707.8\n",
       "converged:                       True   LL-Null:                       -3219.8\n",
       "                                        LLR p-value:                1.109e-221\n",
       "==========================================================================================\n",
       "                             coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
       "------------------------------------------------------------------------------------------\n",
       "Intercept                -13.0762      0.532    -24.600      0.000       -14.118   -12.034\n",
       "residual_sugar             0.3601      0.066      5.431      0.000         0.230     0.490\n",
       "alcohol                    1.0565      0.047     22.343      0.000         0.964     1.149\n",
       "residual_sugar:alcohol    -0.0302      0.006     -4.763      0.000        -0.043    -0.018\n",
       "==========================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.416779\n",
      "         Iterations 6\n"
     ]
    }
   ],
   "source": [
    "model = sm.logit(\n",
    "    \"high_quality ~ residual_sugar + alcohol + residual_sugar:alcohol\",\n",
    "    data = df\n",
    ").fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>   <td>high_quality</td>   <th>  No. Observations:  </th>   <td>  6497</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>   <td>  6493</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>   <td>     3</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Mon, 27 Mar 2017</td> <th>  Pseudo R-squ.:     </th>   <td>0.1590</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>15:43:52</td>     <th>  Log-Likelihood:    </th>  <td> -2707.8</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th>  <td> -3219.8</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>1.109e-221</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "             <td></td>               <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>              <td>  -13.0762</td> <td>    0.532</td> <td>  -24.600</td> <td> 0.000</td> <td>  -14.118   -12.034</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>residual_sugar</th>         <td>    0.3601</td> <td>    0.066</td> <td>    5.431</td> <td> 0.000</td> <td>    0.230     0.490</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>alcohol</th>                <td>    1.0565</td> <td>    0.047</td> <td>   22.343</td> <td> 0.000</td> <td>    0.964     1.149</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>residual_sugar:alcohol</th> <td>   -0.0302</td> <td>    0.006</td> <td>   -4.763</td> <td> 0.000</td> <td>   -0.043    -0.018</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:           high_quality   No. Observations:                 6497\n",
       "Model:                          Logit   Df Residuals:                     6493\n",
       "Method:                           MLE   Df Model:                            3\n",
       "Date:                Mon, 27 Mar 2017   Pseudo R-squ.:                  0.1590\n",
       "Time:                        15:43:52   Log-Likelihood:                -2707.8\n",
       "converged:                       True   LL-Null:                       -3219.8\n",
       "                                        LLR p-value:                1.109e-221\n",
       "==========================================================================================\n",
       "                             coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
       "------------------------------------------------------------------------------------------\n",
       "Intercept                -13.0762      0.532    -24.600      0.000       -14.118   -12.034\n",
       "residual_sugar             0.3601      0.066      5.431      0.000         0.230     0.490\n",
       "alcohol                    1.0565      0.047     22.343      0.000         0.964     1.149\n",
       "residual_sugar:alcohol    -0.0302      0.006     -4.763      0.000        -0.043    -0.018\n",
       "==========================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.491511\n",
      "         Iterations 6\n"
     ]
    }
   ],
   "source": [
    "model = sm.logit(\n",
    "    \"high_quality ~ color\",\n",
    "    data = df\n",
    ").fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>   <td>high_quality</td>   <th>  No. Observations:  </th>  <td>  6497</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>  6495</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>     1</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Mon, 27 Mar 2017</td> <th>  Pseudo R-squ.:     </th> <td>0.008222</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>15:44:03</td>     <th>  Log-Likelihood:    </th> <td> -3193.3</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -3219.8</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>3.429e-13</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "         <td></td>           <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>      <td>   -1.8514</td> <td>    0.073</td> <td>  -25.355</td> <td> 0.000</td> <td>   -1.995    -1.708</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>color[T.white]</th> <td>    0.5647</td> <td>    0.081</td> <td>    6.985</td> <td> 0.000</td> <td>    0.406     0.723</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:           high_quality   No. Observations:                 6497\n",
       "Model:                          Logit   Df Residuals:                     6495\n",
       "Method:                           MLE   Df Model:                            1\n",
       "Date:                Mon, 27 Mar 2017   Pseudo R-squ.:                0.008222\n",
       "Time:                        15:44:03   Log-Likelihood:                -3193.3\n",
       "converged:                       True   LL-Null:                       -3219.8\n",
       "                                        LLR p-value:                 3.429e-13\n",
       "==================================================================================\n",
       "                     coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
       "----------------------------------------------------------------------------------\n",
       "Intercept         -1.8514      0.073    -25.355      0.000        -1.995    -1.708\n",
       "color[T.white]     0.5647      0.081      6.985      0.000         0.406     0.723\n",
       "==================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "PerfectSeparationError",
     "evalue": "Perfect separation detected, results not available",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPerfectSeparationError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-57e1859a615e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model = sm.logit(\n\u001b[1;32m      2\u001b[0m     \u001b[0;34m\"high_quality ~ color : quality\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m ).fit()\n",
      "\u001b[0;32m/Users/mattbrems/anaconda2/lib/python2.7/site-packages/statsmodels/discrete/discrete_model.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, start_params, method, maxiter, full_output, disp, callback, **kwargs)\u001b[0m\n\u001b[1;32m   1374\u001b[0m         bnryfit = super(Logit, self).fit(start_params=start_params,\n\u001b[1;32m   1375\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxiter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfull_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1376\u001b[0;31m                 disp=disp, callback=callback, **kwargs)\n\u001b[0m\u001b[1;32m   1377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1378\u001b[0m         \u001b[0mdiscretefit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogitResults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbnryfit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mattbrems/anaconda2/lib/python2.7/site-packages/statsmodels/discrete/discrete_model.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, start_params, method, maxiter, full_output, disp, callback, **kwargs)\u001b[0m\n\u001b[1;32m    201\u001b[0m         mlefit = super(DiscreteModel, self).fit(start_params=start_params,\n\u001b[1;32m    202\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxiter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfull_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m                 disp=disp, callback=callback, **kwargs)\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmlefit\u001b[0m \u001b[0;31m# up to subclasses to wrap results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mattbrems/anaconda2/lib/python2.7/site-packages/statsmodels/base/model.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, start_params, method, maxiter, full_output, disp, fargs, callback, retall, skip_hessian, **kwargs)\u001b[0m\n\u001b[1;32m    423\u001b[0m                                                        \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m                                                        \u001b[0mretall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretall\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m                                                        full_output=full_output)\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m         \u001b[0;31m#NOTE: this is for fit_regularized and should be generalized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mattbrems/anaconda2/lib/python2.7/site-packages/statsmodels/base/optimizer.pyc\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, objective, gradient, start_params, fargs, kwargs, hessian, method, maxiter, full_output, disp, callback, retall)\u001b[0m\n\u001b[1;32m    182\u001b[0m                             \u001b[0mdisp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxiter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                             \u001b[0mretall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfull_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m                             hess=hessian)\n\u001b[0m\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;31m# this is stupid TODO: just change this to something sane\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mattbrems/anaconda2/lib/python2.7/site-packages/statsmodels/base/optimizer.pyc\u001b[0m in \u001b[0;36m_fit_newton\u001b[0;34m(f, score, start_params, fargs, kwargs, disp, maxiter, callback, retall, full_output, hess, ridge_factor)\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m         \u001b[0miterations\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0mfval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# this is the negative likelihood\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mattbrems/anaconda2/lib/python2.7/site-packages/statsmodels/discrete/discrete_model.pyc\u001b[0m in \u001b[0;36m_check_perfect_pred\u001b[0;34m(self, params, *args)\u001b[0m\n\u001b[1;32m    184\u001b[0m                 np.allclose(fittedvalues - endog, 0)):\n\u001b[1;32m    185\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Perfect separation detected, results not available\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mPerfectSeparationError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     def fit(self, start_params=None, method='newton', maxiter=35,\n",
      "\u001b[0;31mPerfectSeparationError\u001b[0m: Perfect separation detected, results not available"
     ]
    }
   ],
   "source": [
    "model = sm.logit(\n",
    "    \"high_quality ~ color : quality\",\n",
    "    data = df\n",
    ").fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
