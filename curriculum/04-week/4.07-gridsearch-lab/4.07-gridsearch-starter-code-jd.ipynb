{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import patsy\n",
    "import sklearn.linear_model as linear_model\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in data and conduct an exploratory data analysis.\n",
    "#### Resolve any data issues you identify and articulate why you did what you did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sf_crime = pd.read_csv('datasets/sf_crime_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sf_crime.head()\n",
    "\n",
    "## since we will be predicting violent crime versus non-violent crime versus non-crimes\n",
    "## which are based off of category, we can drop 'descript'\n",
    "## can also drop address because there could be plenty of formatting variations\n",
    "## and we have x,y as lat, long\n",
    "\n",
    "sf_crime.drop(['Descript','Address'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## convert dayofweek to numbers so that if we need to look at data by day,\n",
    "## we can have the days in the correct order\n",
    "\n",
    "sf_crime.day = [1 if day == 'Sunday' else 2 if day == 'Monday' else 3 if day == 'Tuesday' else 4 if day == 'Wednesday' else 5 if day == 'Thursday' else 6 if day == 'Friday' else 7 for day in sf_crime.DayOfWeek]\n",
    "sf_crime.drop('DayOfWeek', inplace=True, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create column for hour, month, and year from 'Dates' column.\n",
    "##### Hint: pd.to_datetime may be helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sf_crime['Dates'] = pd.to_datetime(sf_crime.Dates)\n",
    "\n",
    "sf_crime['hour'] = sf_crime.Dates.dt.hour\n",
    "sf_crime['month'] = sf_crime.Dates.dt.month\n",
    "sf_crime['year'] = sf_crime.Dates.dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a logit model predicting violent crime versus non-violent crime versus non-crimes.\n",
    "\n",
    "##### We've given you the various crimes that fall into specific categories so you can use these to create these subcategories \n",
    "\n",
    "#### Non-Violent Crimes: bad checks, bribery, drug/narcotic, drunkenness, embezzlement, forgery/counterfeiting, fraud, gambling, liquor, loitering, trespass.\n",
    "\n",
    "#### Non-Crimes: non-criminal, runaway, secondary codes, suspicious occ, warrants.\n",
    "\n",
    "#### Violent Crimes: everything else.\n",
    "\n",
    "###### Hint: What type of model do you need here? What should your \"baseline\" category be?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Need a logistic regression model\n",
    "baseline = violent crime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit a model with five folds and lasso regularization\n",
    "#### Use Cs=15 to test a grid of 15 distinct parameters\n",
    "#### Remember: Cs describes the inverse of regularization strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import patsy\n",
    "nvc = ['BAD CHECKS', 'BRIBERY', 'DRUG/NARCOTIC', 'DRUNKENNESS', 'EMBEZZLEMENT', 'FORGERY/COUNTERFEITING', 'FRAUD', 'GAMBLING', 'LIQUOR', 'LOITERING', 'TRESSPASS']\n",
    "nc = ['NON-CRIMINAL', 'RUNAWAY', 'SECONDARY CODES', 'SUSPICIOUS OCC', 'WARRANTS']\n",
    "\n",
    "sf_crime['Subcategory'] = ['Non-Violent Crime' if x in nvc else 'Non-Crime' if x in nc else 'Violent Crime' for x in sf_crime['Category']]\n",
    "\n",
    "sf_crime['NV'] = [1 if x=='Non-Violent Crime' else 0 for x in sf_crime.Subcategory ]\n",
    "sf_crime['VC'] = [1 if x=='Violent Crime' else 0 for x in sf_crime.Subcategory ]\n",
    "sf_crime['NC'] = [1 if x=='Non-Crime' else 0 for x in sf_crime.Subcategory ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = patsy.dmatrix('~ C(PdDistrict) + C(Resolution)', sf_crime)\n",
    "X = pd.DataFrame(X, columns=X.design_info.column_names)\n",
    "\n",
    "y = sf_crime.Subcategory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=77)\n",
    "\n",
    "\n",
    "logreg_cv = LogisticRegressionCV(solver='liblinear', Cs=15, cv=5, penalty='l1',scoring='accuracy')\n",
    "logreg_cv.fit(X_train, y_train)\n",
    "logreg_cv.score(X_test, y_test)\n",
    "y_pred = logreg_cv.predict(X_test)\n",
    "y_score = logreg_cv.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " best C for class:\n",
      "{'Violent Crime': 3.7275937203149381, 'Non-Violent Crime': 0.0001, 'Non-Crime': 13.89495494373136}\n"
     ]
    }
   ],
   "source": [
    "# find best C per class\n",
    "print('best C for class:')\n",
    "best_C = {logreg_cv.classes_[i]:x for i, (x, c) in enumerate(zip(logreg_cv.C_, logreg_cv.classes_))}\n",
    "print(best_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Non-Crime PREDICTED</th>\n",
       "      <th>Non-Violent Crime PREDICTED</th>\n",
       "      <th>Violent Crime PREDICTED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Non-Crime TRUE</th>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>1181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Non-Violent Crime TRUE</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Violent Crime TRUE</th>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>4294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Non-Crime PREDICTED  Non-Violent Crime PREDICTED  \\\n",
       "Non-Crime TRUE                           87                            0   \n",
       "Non-Violent Crime TRUE                    7                            0   \n",
       "Violent Crime TRUE                       43                            0   \n",
       "\n",
       "                        Violent Crime PREDICTED  \n",
       "Non-Crime TRUE                             1181  \n",
       "Non-Violent Crime TRUE                      328  \n",
       "Violent Crime TRUE                         4294  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm = pd.DataFrame(cm, columns=(logreg_cv.classes_ + ' PREDICTED'), index=(logreg_cv.classes_ + ' TRUE'))\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit regular logit model to 'DRUG/NARCOTIC' and 'BURGLARY' classes; be sure to specify the Y = 1 and Y = 0 classes. Use lasso penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best C for class:\n",
      "{'Non-Violent Crime': 1.0}\n",
      "Classification report:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "Non-Violent Crime       0.77      0.90      0.83       157\n",
      "    Violent Crime       0.93      0.83      0.88       249\n",
      "\n",
      "      avg / total       0.87      0.86      0.86       406\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.formula.api as sm\n",
    "import pandas as pd\n",
    "\n",
    "sf = sf_crime[sf_crime.Category.isin(['DRUG/NARCOTIC','BURGLARY'])]\n",
    "sf['Subcat_num'] = [1 if x=='Violent Crime' else 0 for x in sf.Subcategory]\n",
    "\n",
    "X = patsy.dmatrix('~ C(PdDistrict) + C(Resolution)', sf)\n",
    "X = pd.DataFrame(X, columns=X.design_info.column_names)\n",
    "\n",
    "y = sf.Subcategory\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=77)\n",
    "\n",
    "\n",
    "logreg_cv = LogisticRegressionCV(solver='liblinear', Cs=15, cv=5, penalty='l1')\n",
    "logreg_cv.fit(X_train, y_train)\n",
    "logreg_cv.score(X_test, y_test)\n",
    "y_pred = logreg_cv.predict(X_test)\n",
    "\n",
    "# find best C per class\n",
    "print('best C for class:')\n",
    "best_C = {logreg_cv.classes_[i]:x for i, (x, c) in enumerate(zip(logreg_cv.C_, logreg_cv.classes_))}\n",
    "print(best_C)\n",
    "print 'Classification report:\\n', classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Build confusion matrices for the models above\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run gridsearch using GridSearchCV and 5 folds\n",
    "#### Score on accuracy; what does this metric tell us?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],'penalty':['l1','l2'] }\n",
    "clf = GridSearchCV(LogisticRegression(), param_grid, cv=5,scoring='accuracy')\n",
    "clf = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86374695863746964"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Find the best parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'penalty': 'l1'}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Use this parameter to .fit, .predict, and print a classification_report (we've already imported this for you) for our X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:  0.85960591133\n",
      "\n",
      "Classification report:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "Non-Violent Crime       0.77      0.90      0.83       157\n",
      "    Violent Crime       0.93      0.83      0.88       249\n",
      "\n",
      "      avg / total       0.87      0.86      0.86       406\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg_gs = LogisticRegression(penalty='l1',C=1).fit(X_train, y_train)\n",
    "logreg_gs.score(X_test, y_test)\n",
    "y_pred = logreg_gs.predict(X_test)\n",
    "\n",
    "print 'Accuracy Score: ',accuracy_score(y_test, y_pred)\n",
    "print \n",
    "print 'Classification report:\\n', classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### When looking at the classification report, remember:\n",
    "##### Precision = True Positives / (True Positives + False Positives)\n",
    "\n",
    "A precision score of 1 indicates that the classifier never mistakenly added observations from another class. A precision score of 0 would mean that the classifier misclassified every instance of the current class.\n",
    " \n",
    "##### Recall = True Positives / (True Positives + False Negatives)\n",
    "A recall score of 1 indicates that the classifier correctly predicted (found) all observations of the current class (by implication, no false negatives, or misclassifications of the current class). A recall score of 0 alternatively means that the classifier missed all observations of the current class.\n",
    "\n",
    "##### F1-Score = 2 * (Precision * Recall) / (Precision + Recall)\n",
    "The f1-score's best value is 1 and worst value is 0, like the precision and recall scores. It is a useful metric for taking into account both measures at once. \n",
    "\n",
    "##### Support is simply the number of observations of the labelled class.\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
