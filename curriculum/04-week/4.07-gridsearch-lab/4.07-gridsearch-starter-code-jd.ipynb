{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import patsy\n",
    "import sklearn.linear_model as linear_model\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in data and conduct an exploratory data analysis.\n",
    "#### Resolve any data issues you identify and articulate why you did what you did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sf_crime = pd.read_csv('datasets/sf_crime_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sf_crime.head()\n",
    "\n",
    "## since we will be predicting violent crime versus non-violent crime versus non-crimes\n",
    "## which are based off of category, we can drop 'descript'\n",
    "## can also drop address because there could be plenty of formatting variations\n",
    "## and we have x,y as lat, long\n",
    "\n",
    "sf_crime.drop(['Descript','Address'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## convert dayofweek to numbers so that if we need to look at data by day,\n",
    "## we can have the days in the correct order\n",
    "\n",
    "sf_crime.day = [1 if day == 'Sunday' else 2 if day == 'Monday' else 3 if day == 'Tuesday' else 4 if day == 'Wednesday' else 5 if day == 'Thursday' else 6 if day == 'Friday' else 7 for day in sf_crime.DayOfWeek]\n",
    "sf_crime.drop('DayOfWeek', inplace=True, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create column for hour, month, and year from 'Dates' column.\n",
    "##### Hint: pd.to_datetime may be helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print sf_crime.head()\n",
    "sf_crime['Dates'] = pd.to_datetime(sf_crime.Dates)\n",
    "\n",
    "sf_crime['hour'] = sf_crime.Dates.dt.hour\n",
    "sf_crime['month'] = sf_crime.Dates.dt.month\n",
    "sf_crime['year'] = sf_crime.Dates.dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a logit model predicting violent crime versus non-violent crime versus non-crimes.\n",
    "\n",
    "##### We've given you the various crimes that fall into specific categories so you can use these to create these subcategories \n",
    "\n",
    "#### Non-Violent Crimes: bad checks, bribery, drug/narcotic, drunkenness, embezzlement, forgery/counterfeiting, fraud, gambling, liquor, loitering, trespass.\n",
    "\n",
    "#### Non-Crimes: non-criminal, runaway, secondary codes, suspicious occ, warrants.\n",
    "\n",
    "#### Violent Crimes: everything else.\n",
    "\n",
    "###### Hint: What type of model do you need here? What should your \"baseline\" category be?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Need a logistic regression model\n",
    "baseline = violent crime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit a model with five folds and lasso regularization\n",
    "#### Use Cs=15 to test a grid of 15 distinct parameters\n",
    "#### Remember: Cs describes the inverse of regularization strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import patsy\n",
    "nvc = ['BAD CHECKS', 'BRIBERY', 'DRUG/NARCOTIC', 'DRUNKENNESS', 'EMBEZZLEMENT', 'FORGERY/COUNTERFEITING', 'FRAUD', 'GAMBLING', 'LIQUOR', 'LOITERING', 'TRESSPASS']\n",
    "nc = ['NON-CRIMINAL', 'RUNAWAY', 'SECONDARY CODES', 'SUSPICIOUS OCC', 'WARRANTS']\n",
    "\n",
    "sf_crime['Subcategory'] = ['Non-Violent Crime' if x in (nvc) else 'Non-Crime' if x in (nc) else 'Violent Crime' for x in sf_crime['Category']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = patsy.dmatrix('~ C(PdDistrict) + C(Resolution)', sf_crime)\n",
    "X = pd.DataFrame(X, columns=X.design_info.column_names)\n",
    "\n",
    "y = sf_crime.Subcategory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Max auc_roc:', {'Violent Crime': array([[ 0.26997477,  0.26997477,  0.73002523,  0.73002523,  0.73002523,\n",
      "         0.73759462,  0.73759462,  0.73591253,  0.73591253,  0.73507149,\n",
      "         0.73507149,  0.73507149,  0.73507149,  0.73507149,  0.73507149],\n",
      "       [ 0.26997477,  0.26997477,  0.73002523,  0.73002523,  0.73002523,\n",
      "         0.74011775,  0.74011775,  0.74095879,  0.74095879,  0.74095879,\n",
      "         0.74095879,  0.74095879,  0.74095879,  0.74095879,  0.74095879],\n",
      "       [ 0.27020202,  0.27020202,  0.72979798,  0.72979798,  0.72979798,\n",
      "         0.74242424,  0.74242424,  0.74326599,  0.74326599,  0.74326599,\n",
      "         0.74326599,  0.74326599,  0.74326599,  0.74326599,  0.74326599],\n",
      "       [ 0.26958719,  0.26958719,  0.73041281,  0.73041281,  0.73041281,\n",
      "         0.73294019,  0.73294019,  0.73378265,  0.73294019,  0.73294019,\n",
      "         0.73294019,  0.73294019,  0.73294019,  0.73294019,  0.73294019],\n",
      "       [ 0.26958719,  0.26958719,  0.73041281,  0.73041281,  0.73041281,\n",
      "         0.73799495,  0.73799495,  0.73799495,  0.73883741,  0.73883741,\n",
      "         0.73883741,  0.73883741,  0.73883741,  0.73883741,  0.73883741]]), 'Non-Violent Crime': array([[ 0.94365013,  0.94365013,  0.94365013,  0.94365013,  0.94365013,\n",
      "         0.94365013,  0.94365013,  0.94365013,  0.94365013,  0.94365013,\n",
      "         0.94365013,  0.94365013,  0.94365013,  0.94365013,  0.94365013],\n",
      "       [ 0.94365013,  0.94365013,  0.94365013,  0.94365013,  0.94365013,\n",
      "         0.94365013,  0.94365013,  0.94365013,  0.94365013,  0.94365013,\n",
      "         0.94365013,  0.94365013,  0.94365013,  0.94365013,  0.94365013],\n",
      "       [ 0.94360269,  0.94360269,  0.94360269,  0.94360269,  0.94360269,\n",
      "         0.94360269,  0.94360269,  0.94360269,  0.94360269,  0.94360269,\n",
      "         0.94360269,  0.94360269,  0.94360269,  0.94360269,  0.94360269],\n",
      "       [ 0.94355518,  0.94355518,  0.94355518,  0.94355518,  0.94355518,\n",
      "         0.94355518,  0.94355518,  0.94355518,  0.94355518,  0.94355518,\n",
      "         0.94355518,  0.94355518,  0.94355518,  0.94355518,  0.94355518],\n",
      "       [ 0.94355518,  0.94355518,  0.94355518,  0.94355518,  0.94355518,\n",
      "         0.94355518,  0.94355518,  0.94355518,  0.94355518,  0.94355518,\n",
      "         0.94355518,  0.94355518,  0.94355518,  0.94355518,  0.94355518]]), 'Non-Crime': array([[ 0.78637511,  0.78637511,  0.78637511,  0.78637511,  0.78637511,\n",
      "         0.78469302,  0.79394449,  0.79310345,  0.79310345,  0.79310345,\n",
      "         0.79310345,  0.79310345,  0.79310345,  0.79310345,  0.79310345],\n",
      "       [ 0.78637511,  0.78637511,  0.78637511,  0.78637511,  0.78637511,\n",
      "         0.78721615,  0.78973928,  0.79058032,  0.79058032,  0.79058032,\n",
      "         0.79058032,  0.79058032,  0.79058032,  0.79058032,  0.79058032],\n",
      "       [ 0.78619529,  0.78619529,  0.78619529,  0.78619529,  0.78619529,\n",
      "         0.78619529,  0.79545455,  0.7962963 ,  0.7962963 ,  0.7962963 ,\n",
      "         0.7962963 ,  0.7962963 ,  0.7962963 ,  0.7962963 ,  0.7962963 ],\n",
      "       [ 0.78685762,  0.78685762,  0.78685762,  0.78685762,  0.78685762,\n",
      "         0.78854254,  0.789385  ,  0.79022746,  0.789385  ,  0.789385  ,\n",
      "         0.789385  ,  0.789385  ,  0.789385  ,  0.789385  ,  0.789385  ],\n",
      "       [ 0.78685762,  0.78685762,  0.78685762,  0.78685762,  0.78685762,\n",
      "         0.78685762,  0.79275484,  0.7935973 ,  0.7935973 ,  0.7935973 ,\n",
      "         0.7935973 ,  0.7935973 ,  0.7935973 ,  0.7935973 ,  0.7935973 ]])})\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "        Non-Crime       0.65      0.07      0.12      1268\n",
      "Non-Violent Crime       0.00      0.00      0.00       335\n",
      "    Violent Crime       0.74      0.99      0.85      4337\n",
      "\n",
      "      avg / total       0.68      0.74      0.64      5940\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  86,    0, 1182],\n",
       "       [   7,    0,  328],\n",
       "       [  39,    0, 4298]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=77)\n",
    "\n",
    "\n",
    "logreg_cv = LogisticRegressionCV(solver='liblinear', Cs=15, cv=5, penalty='l1')\n",
    "logreg_cv.fit(X_test, y_test)\n",
    "logreg_cv.score(X_test, y_test)\n",
    "y_pred = logreg_cv.predict(X_test)\n",
    "print ('Max auc_roc:', logreg_cv.scores_)\n",
    "\n",
    "# 0.79562658\n",
    "\n",
    "#Classification report:\n",
    "from sklearn.metrics import classification_report\n",
    "print classification_report(y_test, y_pred)\n",
    "\n",
    "\n",
    "#Confusion Matrix:\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm\n",
    "# array([[ 421, 1182],\n",
    "#        [  39, 4298]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best C for class:\n",
      "{0.0: 1.0}\n"
     ]
    }
   ],
   "source": [
    "# find best C per class\n",
    "print('best C for class:')\n",
    "best_C = {logreg_cv.classes_[i]:x for i, (x, c) in enumerate(zip(logreg_cv.C_, logreg_cv.classes_))}\n",
    "print(best_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Non-Crime PREDICTED</th>\n",
       "      <th>Non-Violent Crime PREDICTED</th>\n",
       "      <th>Violent Crime PREDICTED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Non-Crime TRUE</th>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>1182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Non-Violent Crime TRUE</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Violent Crime TRUE</th>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>4298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Non-Crime PREDICTED  Non-Violent Crime PREDICTED  \\\n",
       "Non-Crime TRUE                           86                            0   \n",
       "Non-Violent Crime TRUE                    7                            0   \n",
       "Violent Crime TRUE                       39                            0   \n",
       "\n",
       "                        Violent Crime PREDICTED  \n",
       "Non-Crime TRUE                             1182  \n",
       "Non-Violent Crime TRUE                      328  \n",
       "Violent Crime TRUE                         4298  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm = pd.DataFrame(cm, columns=(logreg_cv.classes_ + ' PREDICTED'), index=(logreg_cv.classes_ + ' TRUE'))\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit regular logit model to 'DRUG/NARCOTIC' and 'BURGLARY' classes; be sure to specify the Y = 1 and Y = 0 classes. Use lasso penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as sm\n",
    "import pandas as pd\n",
    "\n",
    "model = sm.logit(\n",
    "    \"Subcategory ~ \",\n",
    "    data = sf_crime\n",
    ").fit()\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Build confusion matrices for the models above\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run gridsearch using GridSearchCV and 5 folds\n",
    "#### Score on accuracy; what does this metric tell us?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "C_vals = [0.0001, 0.001, 0.01, 0.1, 0.5, 0.75, 1.0, 2.5, 5.0, 10.0, 100.0, 1000.0]\n",
    "penalties = ['l1','l2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Find the best parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Use this parameter to .fit, .predict, and print a classification_report (we've already imported this for you) for our X and Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### When looking at the classification report, remember:\n",
    "##### Precision = True Positives / (True Positives + False Positives)\n",
    "\n",
    "A precision score of 1 indicates that the classifier never mistakenly added observations from another class. A precision score of 0 would mean that the classifier misclassified every instance of the current class.\n",
    " \n",
    "##### Recall = True Positives / (True Positives + False Negatives)\n",
    "A recall score of 1 indicates that the classifier correctly predicted (found) all observations of the current class (by implication, no false negatives, or misclassifications of the current class). A recall score of 0 alternatively means that the classifier missed all observations of the current class.\n",
    "\n",
    "##### F1-Score = 2 * (Precision * Recall) / (Precision + Recall)\n",
    "The f1-score's best value is 1 and worst value is 0, like the precision and recall scores. It is a useful metric for taking into account both measures at once. \n",
    "\n",
    "##### Support is simply the number of observations of the labelled class.\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
