{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "69b9a648-bcc7-490d-9f9b-ea244d156bd6"
   },
   "source": [
    "# Web Scraping for Indeed.com & Predicting Salaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "34681254-c802-462f-829d-8894d0772d08"
   },
   "source": [
    "### Problem Statement:\n",
    "#### Can salaries for Data Scientist job listings be predicted as high or low, in comparison to the median salary posted, using various features of the posting? What will best predict whether it's higher or lower than the median?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions to grab the job title, company, location, salary, and brief description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis for Principal\n",
    "\n",
    "https://docs.google.com/document/d/16qF3YIrw4OdYrzfc9DpSkoTCKnOisrbD1_UR5Wr4BJw/edit?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## use various IDs, classes to identify the features\n",
    "## if they cannot be found, an error will be thrown,\n",
    "## and we will simply pass that attribute and move on\n",
    "\n",
    "def get_job(webpage):\n",
    "    tag = webpage.find('a', title=True, attrs={'data-tn-element':'jobTitle'})\n",
    "    try:\n",
    "        return tag['title']\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "def get_company(webpage):\n",
    "    tag = webpage.find('span', attrs={'class':'company'})\n",
    "    try:\n",
    "        return tag.text.strip('\\n')\n",
    "    except:\n",
    "        pass\n",
    "def get_location(webpage):\n",
    "    tag = webpage.find('span', attrs={'class':'location'})\n",
    "    try:\n",
    "        return tag.text\n",
    "    except:\n",
    "        pass    \n",
    "\n",
    "def get_salary(webpage):\n",
    "    try:\n",
    "        return webpage.find('table').tr.td.nobr.renderContents() ## for regular listings\n",
    "    except:\n",
    "        try:\n",
    "            return webpage.find('div').div.text ## for sponsored listings\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "def get_description(webpage):\n",
    "    description = webpage.find('span', attrs={'itemprop':\"description\"})\n",
    "    try:\n",
    "        return description.text.strip('\\n')\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "6e259594-1c52-436b-ab9e-527e071941c1"
   },
   "outputs": [],
   "source": [
    "###############\n",
    "###############\n",
    "### I chose to write a function to combine some of the steps\n",
    "### I also chose not to clean the salaries each time, but instead\n",
    "### will just clean them all at once, when I import the data from the csvs\n",
    "### pps I am not limiting my search to particular cities\n",
    "###############\n",
    "###############\n",
    "\n",
    "\n",
    "## first, define two functions that will be used in \n",
    "## the main scraping function: str_number_to_number, compile_files\n",
    "\n",
    "\n",
    "# given a string of a number with commas, convert to float\n",
    "def str_number_to_number(string):\n",
    "    import locale \n",
    "    string = string.strip('$')\n",
    "    locale.setlocale(locale.LC_ALL, 'en_US.UTF-8') #for american comma notation\n",
    "    # if european comma notation needed, change 2nd parameter to 'fr_FR'\n",
    "    num = locale.atof(string)\n",
    "    return float(num)\n",
    "\n",
    "\n",
    "## import the results that have been previously exported into df\n",
    "def compile_files():\n",
    "    import glob\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    indeed_csvs = '../indeed/'\n",
    "    files = glob.glob(indeed_csvs + '*.csv') # get a list of the csv files\n",
    "    indeed_final = pd.DataFrame(columns=['job','company','location','salary','description'])\n",
    "    for f in files: # read each csv file in\n",
    "        f = pd.read_csv(f, names=['job','company','location','salary','description'],low_memory=False)\n",
    "        indeed_final = indeed_final.append(f)\n",
    "    indeed_final.drop_duplicates(inplace=True)\n",
    "    return indeed_final\n",
    "\n",
    "\n",
    "######################################################\n",
    "######################################################\n",
    "################    SCRAPE TIME!!    #################\n",
    "######################################################\n",
    "######################################################\n",
    "\n",
    "\n",
    "def scrape_indeed():\n",
    "    \n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    import datetime\n",
    "    import time\n",
    "    import re\n",
    "    import numpy as np\n",
    " \n",
    "    \n",
    "    ## compile previously scraped results to see if there are new jobs to add\n",
    "    indeed = compile_files()    \n",
    "    base = len(indeed)\n",
    "    ## record start time to calculate elapsed time\n",
    "    start = datetime.datetime.now()\n",
    "    \n",
    "    print 'Start time: ',start.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    print 'Base file has ', base, ' records'\n",
    "\n",
    "    ## add '&fromage=last' to the url to get newly added jobs that might be skipped over otherwise\n",
    "    ## end the url at start= so we can dynamically flip through all pages of listings\n",
    "    url = \"http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&fromage=last&start=\"\n",
    "\n",
    "    ## x will indicate the number of the first listing on a particular page \n",
    "    ## each page lists 10 posts (and 5 sponsored posts)\n",
    "    x = 0\n",
    "    url_start = url+str(x)\n",
    "    page = requests.get(url_start).content\n",
    "    soup = BeautifulSoup(page,'lxml')\n",
    "    \n",
    "    print 'Page scraped & souped'\n",
    "    \n",
    "    ## take the full line that says 'Jobs x to y of z' and turn into a list\n",
    "    ## use to end the page loop -- function will stop looking \n",
    "    ## to the next page once it hits the last results\n",
    "    for results in soup.find('div', attrs={'id':'searchCount'}):\n",
    "        count = str(results).split()    \n",
    "        total = count[len(count)-1]          # set total to z, the total number o[f results\n",
    "        total = str_number_to_number(total)  # since there are commas if the number > 999, this function will deal with that and convert to int\n",
    "\n",
    "        \n",
    "    while x <= total-9:\n",
    "        ## go to new page of listings\n",
    "        url_new_page = url + str(x)\n",
    "        page = requests.get(url_new_page).content\n",
    "        soup = BeautifulSoup(page)\n",
    "        \n",
    "        ## record which number of listings we're at\n",
    "        ## for process notifications\n",
    "        for num_listings in  soup.find('div', attrs={'id':'searchCount'}) :\n",
    "            num_listings = num_listings.split()[3]\n",
    "        \n",
    "        main = soup.find('td',{'id':'resultsCol'})   # limit our searching to solely the results portion of the page\n",
    "        results = main.find_all('div', {'class': re.compile(\"result$\")}) # create a list consisting only of the 15 results\n",
    "\n",
    "        ## results has a list of the 10 listings on the page, plus the 5 sponsored\n",
    "        ## loop through each listing and get the job, company, location, salary, and decription info\n",
    "        for i in range(len(results)):\n",
    "            job = get_job(results[i])\n",
    "            company = get_company(results[i]) \n",
    "            location = get_location(results[i])\n",
    "            salary = get_salary(results[i])\n",
    "            description = get_description(results[i])\n",
    "\n",
    "            add_job = [job, company, location, salary, description]\n",
    "            indeed.append(add_job) ## add to main df\n",
    "\n",
    "        ## move to next page of results\n",
    "        x+=10\n",
    "        new = len(indeed) - base\n",
    "        elapsed = datetime.datetime.now() - start\n",
    "        remaining = total - x\n",
    "        est_pages = remaining/10\n",
    "        \n",
    "        ## print update after each page bc impatient\n",
    "        print 'Added ', new, ' jobs-- scraped ',num_listings,' of ', total, ' listings in ', elapsed, '; ', est_pages, ' pages remaining'\n",
    "        \n",
    "        time.sleep(0.5) ## wait a little to request the next page\n",
    "            \n",
    "    finish = datetime.datetime.now()\n",
    "    now = finish.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    print 'Finish time: ',now\n",
    "\n",
    "    elapsed = finish-start\n",
    "    print 'Elapsed: ',elapsed\n",
    "    indeed = pd.DataFrame(indeed)\n",
    "    \n",
    "    ## send results to csv file\n",
    "    indeed.to_csv('../indeed/'+now+'.csv',sep=',', encoding='utf-8',header=False,index=False)\n",
    "    return indeed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "04563b69-f7b6-466f-9d65-fc62c9ddee6a"
   },
   "source": [
    "## Predicting salaries using Random Forests + Another Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "243e949e-2742-40af-872e-fec475fd306c"
   },
   "source": [
    "#### Load in the the data of scraped salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "588f9845-6143-4bcc-bfd1-85d45b79303d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5194"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## YOUR CODE HERE\n",
    "\n",
    "indeed = compile_files()\n",
    "indeed.reset_index(drop=True)\n",
    "len(indeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "### CLEAN UP SALARIES\n",
    "###\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "## create a sub-df consisting only of jobs with annual salaries\n",
    "df=indeed[indeed.salary.notnull()&indeed.salary.str.contains('year')]\n",
    "df.salary = df.salary.astype(str)\n",
    "\n",
    "## turn the salary into a list so we can grab the high and low ends, then average\n",
    "df['salary_list'] = df.salary.str.split()\n",
    "\n",
    "mask = df.salary.str.contains('-')\n",
    "df['low_end'], df['high_end'], df['salary_clean'] = np.NaN, np.NaN, np.NaN\n",
    "df['low_end'][mask] = map(lambda x: x[0],df.salary_list.loc[mask])\n",
    "df['high_end'][mask] = map(lambda x: x[2],df.salary_list.loc[mask])\n",
    "\n",
    "df.low_end[df.high_end==1] = np.NaN\n",
    "df.high_end[df.high_end==1] = np.NaN\n",
    "\n",
    "df.salary_clean[df.salary.notnull()]= [x[0] for x in df.salary_list[df.salary_list.notnull()]]\n",
    "df.salary_clean[df.low_end.notnull()&df.high_end.notnull()] = np.NaN\n",
    "\n",
    "for col in ['salary_clean','low_end','high_end']:\n",
    "    df[col][df[col].notnull()] = [str_number_to_number(x) for x in df[col][df[col].notnull()]]\n",
    "\n",
    "# average out ranges\n",
    "df.salary_clean[df.salary_clean.isnull()] = (df.low_end + df.high_end) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "c7631f51-07f2-4c79-a093-3e9bc7849a48"
   },
   "source": [
    "#### We want to predict a binary variable - whether the salary was low or high. Compute the median salary and create a new binary variable that is true when the salary is high (above the median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "c20d2498-151c-44c3-a453-3a333c79a0ac"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "### BINARY TARGET FEATURE -- above (1) median or below (0) \n",
    "###\n",
    "\n",
    "\n",
    "df = df[df.salary_clean.notnull()]\n",
    "median_salary = np.median(df.salary_clean)\n",
    "df['high_salary'] = 1\n",
    "df['high_salary'][df.salary_clean <= median_salary] = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87204.0"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median_salary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "a7afb2c0-d41e-4779-8216-91cd8dd4473f"
   },
   "source": [
    "#### Thought experiment: What is the baseline accuracy for this model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.5,  0.5,  0.5])"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###\n",
    "### LOGISTIC REGRESSION MODEL\n",
    "###\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "dummies = pd.get_dummies(df[['job','company','location']])\n",
    "\n",
    "X = pd.concat([dummies, df['salary_clean']], axis=1)\n",
    "y = df.high_salary\n",
    "\n",
    "cross_val_score(LogisticRegression(), X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "4fb29de2-5b98-474c-a4ad-5170b72b9aea"
   },
   "source": [
    "#### Create a Random Forest model to predict High/Low salary using Sklearn. Start by ONLY using the location as a feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###\n",
    "### CLEAN UP LOCATIONS -- parse to city, state\n",
    "###\n",
    "\n",
    "\n",
    "## remove areas in parentheses\n",
    "df.location = df.location.str.replace('\\((.*?)\\)','')\n",
    "df.location = df.location.str.strip()\n",
    "\n",
    "## remove zip codes\n",
    "df.location = df.location.str.replace(r'(\\d{5}(\\-\\d{4})?)$','')\n",
    "df.location = df.location.str.strip()\n",
    "\n",
    "## create feature with states\n",
    "df['state'] = df.location.str.findall('\\,\\s(\\D{2})$')\n",
    "\n",
    "## remove state from location\n",
    "df.location = df.location.str.replace('(\\,\\s\\D{2})$','')\n",
    "\n",
    "## take the states out of the list they were for some reason placed in\n",
    "df.state = df.state.astype(str)\n",
    "df.state = df.state.str.replace('(\\[)','')\n",
    "df.state = df.state.str.replace('(\\])','')\n",
    "df.state = df.state.str.replace('(\\')','')\n",
    "\n",
    "df.company = df.company.str.strip()\n",
    "df.company = df.company.str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###\n",
    "### DUM DUMS!!!!\n",
    "###\n",
    "\n",
    "\n",
    "X = pd.get_dummies(df[['location','state']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "ddbc6159-6854-4ca7-857f-bfecdaf6d9c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.ensemble.forest.RandomForestClassifier'> Score:\t0.67 ± 0.02\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "### RANDOM FOREST MODEL\n",
    "###\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, BaggingClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "def classify(Classifier, X, y, weight):\n",
    "    name = str(Classifier)\n",
    "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=41)\n",
    "    if weight != '':\n",
    "        dt = Classifier(class_weight=weight)\n",
    "    else:\n",
    "        dt = Classifier()\n",
    "    s = cross_val_score(dt, X, y, cv=cv, n_jobs=-1)\n",
    "    print \"{} Score:\\t{:0.3} ± {:0.3}\".format(name, s.mean().round(3), s.std().round(3))\n",
    "\n",
    "## output baseline score\n",
    "classify(RandomForestClassifier, X, y, 'balanced')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "0ef04f32-419c-4bf2-baf7-48201f03df89"
   },
   "source": [
    "#### Create a few new variables in your dataframe to represent interesting features of a job title.\n",
    "- For example, create a feature that represents whether 'Senior' is in the title \n",
    "- or whether 'Manager' is in the title. \n",
    "- Then build a new Random Forest with these features. Do they add any value? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "068dc1cf-7fd7-4f27-a1f1-7f0a5a221d29"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "### JOB TITLE VARIABLES\n",
    "###\n",
    "\n",
    "\n",
    "df.job = df.job.str.upper()\n",
    "df['analyst'] = 0\n",
    "df['analyst'][df.job.str.contains('ANALY')] = 1\n",
    "\n",
    "df['statistician'] = 0\n",
    "df['statistician'][df.job.str.contains('STATISTIC')] = 1\n",
    "\n",
    "df['machine_learning'] = 0\n",
    "df['machine_learning'][df.job.str.contains('MACHINE')] = 1\n",
    "\n",
    "df['research'] = 0\n",
    "df['research'][df.job.str.contains('RESEARCH')] = 1\n",
    "\n",
    "df['science'] = 0\n",
    "df['science'][df.job.str.contains('SCIEN')] = 1\n",
    "\n",
    "df['engineer'] = 0\n",
    "df['engineer'][df.job.str.contains('ENGIN')] = 1\n",
    "\n",
    "df['entry_level'] = 0\n",
    "df['entry_level'][df.job.str.contains('\\WI\\W')] = 1\n",
    "df['entry_level'][df.job.str.contains('\\WI$')] = 1\n",
    "df['entry_level'][df.job.str.contains('ENTRY_LEVEL')] = 1\n",
    "df['entry_level'][df.job.str.contains('1')] = 1\n",
    "\n",
    "df['mid_level'] = 0\n",
    "df['mid_level'][df.job.str.contains('MANAGER')] = 1\n",
    "df['mid_level'][df.job.str.contains('MID_LEVEL')] = 1\n",
    "df['mid_level'][df.job.str.contains('\\WII\\W')] = 1\n",
    "df['mid_level'][df.job.str.contains('\\WII$')] = 1\n",
    "df['mid_level'][df.job.str.contains('2')] = 1\n",
    "df['mid_level'][df.job.str.contains('ASSISTANT')] = 1\n",
    "\n",
    "df['senior_level'] = 0\n",
    "df['senior_level'][df.job.str.contains('\\WIII\\W')] = 1\n",
    "df['senior_level'][df.job.str.contains('\\WIII$')] = 1\n",
    "df['senior_level'][df.job.str.contains('3')] = 1\n",
    "df['senior_level'][df.job.str.contains('SR\\W')] = 1\n",
    "df['senior_level'][df.job.str.contains('SENIOR')] = 1\n",
    "df['senior_level'][df.job.str.contains('LEAD')] = 1\n",
    "df['senior_level'][df.job.str.contains('PRINCIPAL')] = 1\n",
    "df['senior_level'][df.job.str.contains('DIRECTOR')] = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "9c9274ef-c9f5-4d56-b286-ecc8709eff9f"
   },
   "source": [
    "#### Rebuild this model with the new variables\n",
    "- You can either create the dummy features manually or use the `dmatrix` function from `patsy`\n",
    "- Remember to scale the feature variables as well!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "b76f65cd-cd3a-4e91-af55-12880be7b057"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95895522388059706"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df.job.drop_duplicates(inplace=True)\n",
    "# df.reset_index(inplace=True)\n",
    "\n",
    "dummies = pd.get_dummies(df.location)\n",
    "df_final = pd.concat([dummies, df[['job','company','description','location','high_salary','salary_clean','analyst','engineer','machine_learning','mid_level','entry_level','senior_level']]], axis=1)\n",
    "\n",
    "df_final.job.drop_duplicates(inplace=True)\n",
    "df_final.reset_index(inplace=True)\n",
    "\n",
    "\n",
    "X = pd.concat([dummies, df[['analyst','engineer','machine_learning','mid_level','entry_level','senior_level']]], axis=1)\n",
    "features = X.columns\n",
    "y = list(df.high_salary.values)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "\n",
    "model = RandomForestClassifier().fit(X_train,y_train)\n",
    "model.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "9367beff-72ba-4768-a0ba-a50b335de61d"
   },
   "source": [
    "#### Use cross-validation in scikit-learn to evaluate the model above. \n",
    "- Evaluate the accuracy of the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "269b9e7c-60b5-4a06-8255-881d7395bc1b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.74444444,  0.58888889,  0.69318182])"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(RandomForestClassifier(),X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "fead9b5b-7316-405d-87fd-e144dff0cbeb"
   },
   "source": [
    "#### Continue to incorporate other text features from the title or summary that you believe will predict the salary and examine their coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.097113</td>\n",
       "      <td>analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.048453</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.046459</td>\n",
       "      <td>engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.043286</td>\n",
       "      <td>Reston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.038442</td>\n",
       "      <td>machine_learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.033913</td>\n",
       "      <td>senior_level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.021412</td>\n",
       "      <td>Washington</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.020433</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.020258</td>\n",
       "      <td>Iowa City</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.020251</td>\n",
       "      <td>Manhattan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.019927</td>\n",
       "      <td>San Jose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.018843</td>\n",
       "      <td>mid_level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.018209</td>\n",
       "      <td>Tucson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.016582</td>\n",
       "      <td>Fort Meade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.013889</td>\n",
       "      <td>Tampa Bay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.013714</td>\n",
       "      <td>Seattle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.013674</td>\n",
       "      <td>Los Angeles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.013262</td>\n",
       "      <td>Columbus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.011873</td>\n",
       "      <td>Berkeley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.011314</td>\n",
       "      <td>Frisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.010800</td>\n",
       "      <td>Queens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.010781</td>\n",
       "      <td>Boston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.010196</td>\n",
       "      <td>Morrisville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.009914</td>\n",
       "      <td>Irvine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.009860</td>\n",
       "      <td>Chicago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.009738</td>\n",
       "      <td>Orange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.009041</td>\n",
       "      <td>Silver Spring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.008606</td>\n",
       "      <td>entry_level</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0                 1\n",
       "0   0.097113           analyst\n",
       "1   0.048453          New York\n",
       "2   0.046459          engineer\n",
       "3   0.043286            Reston\n",
       "4   0.038442  machine_learning\n",
       "5   0.033913      senior_level\n",
       "6   0.021412        Washington\n",
       "7   0.020433     United States\n",
       "8   0.020258         Iowa City\n",
       "9   0.020251         Manhattan\n",
       "10  0.019927          San Jose\n",
       "11  0.018843         mid_level\n",
       "12  0.018209            Tucson\n",
       "13  0.016582        Fort Meade\n",
       "14  0.013889         Tampa Bay\n",
       "15  0.013714           Seattle\n",
       "16  0.013674       Los Angeles\n",
       "17  0.013262          Columbus\n",
       "18  0.011873          Berkeley\n",
       "19  0.011314            Frisco\n",
       "20  0.010800            Queens\n",
       "21  0.010781            Boston\n",
       "22  0.010196       Morrisville\n",
       "23  0.009914            Irvine\n",
       "24  0.009860           Chicago\n",
       "25  0.009738            Orange\n",
       "26  0.009041     Silver Spring\n",
       "27  0.008606       entry_level"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance = pd.DataFrame(sorted(zip(model.feature_importances_,features), key=lambda pair: pair[0], reverse=True))\n",
    "feature_importance = feature_importance[0:28]\n",
    "feature_importance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Keywords: research, analyst, statistician, engineer, machine learning\n",
    "## locations: LA, New York (generally)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_train)\n",
    "\n",
    "results = pd.DataFrame(sorted(zip(df_final.analyst, df_final.Reston, df_final['Los Angeles'], df_final.Queens, df_final.engineer, df_final['New York'],df_final.machine_learning,df_final.high_salary,predictions), key=lambda pair: pair[0], reverse=True),columns=['analyst', 'Reston', 'Los Angeles', 'Queens', 'engineer', 'New York','machine_learning','SALARY_HIGH','PREDICTION'])\n",
    "results['CORRECT']='Yes'\n",
    "results['CORRECT'][results.SALARY_HIGH!=results.PREDICTION]='No'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANALYST\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PREDICTION</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CORRECT</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>No</th>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yes</th>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         PREDICTION\n",
       "CORRECT            \n",
       "No               54\n",
       "Yes              50"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print 'ANALYST'\n",
    "results[['CORRECT','PREDICTION']][results.analyst==1].groupby(['CORRECT']).count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENGINEER\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PREDICTION</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CORRECT</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>No</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yes</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         PREDICTION\n",
       "CORRECT            \n",
       "No               13\n",
       "Yes              13"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print 'ENGINEER'\n",
    "results[['CORRECT','PREDICTION']][results.engineer==1].groupby(['CORRECT']).count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MACHINE LEARNING\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PREDICTION</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CORRECT</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>No</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yes</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         PREDICTION\n",
       "CORRECT            \n",
       "No                9\n",
       "Yes               8"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print 'MACHINE LEARNING'\n",
    "results[['CORRECT','PREDICTION']][results.machine_learning==1].groupby(['CORRECT']).count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "12d5edeb-a272-43a0-9977-d951f12fedfb"
   },
   "source": [
    "#### Take ~100 scraped entries with salaries. Convert them to use with your model and predict the salary - which entries have the highest predicted salaries?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84999999999999998"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "random_salaries = df_final.sample(n=120)\n",
    "# X_keep = df_final.features\n",
    "X_random = random_salaries[features]\n",
    "y_random = random_salaries.high_salary\n",
    "\n",
    "model.score(X_random,y_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(X_random)\n",
    "predict_proba = model.predict_proba(X_random)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JOB</th>\n",
       "      <th>COMPANIES</th>\n",
       "      <th>SALARY</th>\n",
       "      <th>ACTUALLY_HIGH</th>\n",
       "      <th>PREDICTED_HIGH</th>\n",
       "      <th>PREDICTION_PROBA</th>\n",
       "      <th>CORRECT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SUPERVISORY HEALTH SCIENTIST</td>\n",
       "      <td>CENTERS FOR DISEASE CONTROL AND PREVENTION</td>\n",
       "      <td>143516.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SUPERVISORY HEALTH SCIENTIST</td>\n",
       "      <td>CENTERS FOR DISEASE CONTROL AND PREVENTION</td>\n",
       "      <td>143516.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>STATISTICIAN III - DIVISION OF PLANNING AND PR...</td>\n",
       "      <td>STATE OF SOUTH CAROLINA</td>\n",
       "      <td>56947.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 JOB  \\\n",
       "0                       SUPERVISORY HEALTH SCIENTIST   \n",
       "1                       SUPERVISORY HEALTH SCIENTIST   \n",
       "2  STATISTICIAN III - DIVISION OF PLANNING AND PR...   \n",
       "\n",
       "                                    COMPANIES    SALARY  ACTUALLY_HIGH  \\\n",
       "0  CENTERS FOR DISEASE CONTROL AND PREVENTION  143516.0              1   \n",
       "1  CENTERS FOR DISEASE CONTROL AND PREVENTION  143516.0              1   \n",
       "2                     STATE OF SOUTH CAROLINA   56947.5              0   \n",
       "\n",
       "   PREDICTED_HIGH  PREDICTION_PROBA CORRECT  \n",
       "0               0               0.2      No  \n",
       "1               1               0.8     Yes  \n",
       "2               0               0.5     Yes  "
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(sorted(zip(df_final.job,df_final.company,df_final.salary_clean,df_final.high_salary,predictions,predict_proba), key=lambda pair: pair[0], reverse=True),columns=['JOB','COMPANIES','SALARY','ACTUALLY_HIGH','PREDICTED_HIGH','PREDICTION_PROBA'])\n",
    "results['CORRECT']='No'\n",
    "results['CORRECT'][results.ACTUALLY_HIGH==results.PREDICTED_HIGH]='Yes'\n",
    "\n",
    "results.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n",
      "68\n",
      "0.433333333333\n"
     ]
    }
   ],
   "source": [
    "print len(results[results.CORRECT=='Yes'])\n",
    "print len(results[results.CORRECT=='No'])\n",
    "print len(results[results.CORRECT=='Yes']) / float(len(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## So, model score ended up being pretty good,\n",
    "## but it looks like only half were predicted correctly -_____-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "3be94357-e551-4094-b784-2df039216d33"
   },
   "source": [
    "### BONUS "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "db045898-1d2d-4af2-8e79-437c4c7546b4"
   },
   "source": [
    "#### Bonus: Use Count Vectorizer from scikit-learn to create features from the text summaries. \n",
    "- Examine using count or binary features in the model\n",
    "- Re-evaluate your models using these. Does this improve the model performance? \n",
    "- What text features are the most valuable? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "4239e458-28bd-4675-8db3-c1d9c02b9854"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "df_final = df_final[df_final.description.notnull()]\n",
    "df_final.fillna(0,inplace=True)\n",
    "df_final.drop(df_final.index[177],inplace=True)\n",
    "\n",
    "cvec = CountVectorizer(stop_words='english')\n",
    "cvec.fit(df_final['description'])\n",
    "\n",
    "\n",
    "cvec_table  = pd.DataFrame(cvec.transform(df_final['description']).todense(),\n",
    "             columns=cvec.get_feature_names())\n",
    "cvec_table = cvec_table.transpose().transpose()\n",
    "cvec_table.reset_index(drop=True)\n",
    "cvec_table.drop([u'analyst', u'company', u'description', u'engineer', u'job'],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76335877862595425"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get species dummies and add to traps df\n",
    "dummies = pd.get_dummies(df_final, columns=['location'])\n",
    "dummies.drop\n",
    "\n",
    "# df = pd.concat([dummies, cvec_table,  df_final[['job','company','description','location','high_salary','salary_clean','analyst','statistician','engineer','machine_learning','research','mid_level','entry_level','senior_level']]], axis=1)\n",
    "# X = pd.concat([dummies, cvec_table, df_final[['analyst','statistician','engineer','machine_learning','research','mid_level','entry_level','senior_level']]], axis=1)\n",
    "# X = dummies.join(cvec_table)\n",
    "X = cvec_table\n",
    "# X.drop(X.index[177],inplace=True)\n",
    "# X.drop([u'analyst', u'company', u'description', u'engineer', u'job','high_salary','salary_clean'],inplace=True,axis=1)\n",
    "X.fillna(0,inplace=True)\n",
    "y = list(df_final.high_salary.values)\n",
    "features = X.columns\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "dtypes_x = pd.DataFrame(list(X_train.dtypes))\n",
    "cols_x = pd.DataFrame(list(X_train.columns),columns=['col'])\n",
    "t = dtypes_x.join(cols_x)\n",
    "# array([dtype('float64'), dtype('uint8'), dtype('O'), dtype('int64')], dtype=object)\n",
    "model = RandomForestClassifier().fit(X_train,y_train)\n",
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t[0] = t[0].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [0, col]\n",
       "Index: []"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[t[0]=='object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76335877862595425"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90909090909090906"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.036928</td>\n",
       "      <td>scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.025302</td>\n",
       "      <td>science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.017085</td>\n",
       "      <td>analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.015024</td>\n",
       "      <td>learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.014556</td>\n",
       "      <td>growing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.012453</td>\n",
       "      <td>analytics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.011077</td>\n",
       "      <td>research</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.010836</td>\n",
       "      <td>data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.009722</td>\n",
       "      <td>develop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.008679</td>\n",
       "      <td>principal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.008568</td>\n",
       "      <td>collection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.008101</td>\n",
       "      <td>survey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.007848</td>\n",
       "      <td>include</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.007524</td>\n",
       "      <td>quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.007421</td>\n",
       "      <td>modeling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.007335</td>\n",
       "      <td>compiles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.007201</td>\n",
       "      <td>review</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.006416</td>\n",
       "      <td>tools</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.006328</td>\n",
       "      <td>team</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.006122</td>\n",
       "      <td>platform</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.005879</td>\n",
       "      <td>meet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.005827</td>\n",
       "      <td>including</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.005741</td>\n",
       "      <td>assist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.005657</td>\n",
       "      <td>salary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.005649</td>\n",
       "      <td>hadoop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.005638</td>\n",
       "      <td>working</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.005633</td>\n",
       "      <td>ll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.005547</td>\n",
       "      <td>intelligence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.005506</td>\n",
       "      <td>sources</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.005470</td>\n",
       "      <td>performing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1562</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>vast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1563</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>vba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1564</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>vegetation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1565</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>vendor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1566</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>verifies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1567</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1568</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>visible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1569</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>visual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1570</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>visualize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1571</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>vital</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1572</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>vlookup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1573</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>vp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1574</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>wa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1575</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>wam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1576</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>want</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1577</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>warehouse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>warehousing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1579</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>washington</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1580</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>way</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1581</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>wayne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1582</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>ways</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1583</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>weapon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1584</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>websites</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1585</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>willingness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1586</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>windows</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1587</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>worked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1588</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>works</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1589</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1590</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>wuermli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1591</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>year</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1592 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      importance       feature\n",
       "0       0.036928     scientist\n",
       "1       0.025302       science\n",
       "2       0.017085      analysis\n",
       "3       0.015024      learning\n",
       "4       0.014556       growing\n",
       "5       0.012453     analytics\n",
       "6       0.011077      research\n",
       "7       0.010836          data\n",
       "8       0.009722       develop\n",
       "9       0.008679     principal\n",
       "10      0.008568    collection\n",
       "11      0.008101        survey\n",
       "12      0.007848       include\n",
       "13      0.007524       quality\n",
       "14      0.007421      modeling\n",
       "15      0.007335      compiles\n",
       "16      0.007201        review\n",
       "17      0.006416         tools\n",
       "18      0.006328          team\n",
       "19      0.006122      platform\n",
       "20      0.005879          meet\n",
       "21      0.005827     including\n",
       "22      0.005741        assist\n",
       "23      0.005657        salary\n",
       "24      0.005649        hadoop\n",
       "25      0.005638       working\n",
       "26      0.005633            ll\n",
       "27      0.005547  intelligence\n",
       "28      0.005506       sources\n",
       "29      0.005470    performing\n",
       "...          ...           ...\n",
       "1562    0.000000          vast\n",
       "1563    0.000000           vba\n",
       "1564    0.000000    vegetation\n",
       "1565    0.000000        vendor\n",
       "1566    0.000000      verifies\n",
       "1567    0.000000         video\n",
       "1568    0.000000       visible\n",
       "1569    0.000000        visual\n",
       "1570    0.000000     visualize\n",
       "1571    0.000000         vital\n",
       "1572    0.000000       vlookup\n",
       "1573    0.000000            vp\n",
       "1574    0.000000            wa\n",
       "1575    0.000000           wam\n",
       "1576    0.000000          want\n",
       "1577    0.000000     warehouse\n",
       "1578    0.000000   warehousing\n",
       "1579    0.000000    washington\n",
       "1580    0.000000           way\n",
       "1581    0.000000         wayne\n",
       "1582    0.000000          ways\n",
       "1583    0.000000        weapon\n",
       "1584    0.000000      websites\n",
       "1585    0.000000   willingness\n",
       "1586    0.000000       windows\n",
       "1587    0.000000        worked\n",
       "1588    0.000000         works\n",
       "1589    0.000000         world\n",
       "1590    0.000000       wuermli\n",
       "1591    0.000000          year\n",
       "\n",
       "[1592 rows x 2 columns]"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Create a df of the features and their scores, descending\n",
    "feature_importances = sorted(zip(model.feature_importances_,features), key=lambda pair: pair[0], reverse=True)\n",
    "feature_importances = pd.DataFrame(feature_importances,columns=['importance','feature'])\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90566037735849059"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## I don't want to use all of the features, just the important ones\n",
    "## even though most have low scores ... \n",
    "features = list(feature_importances.feature[0:36])\n",
    "\n",
    "X = X[features]\n",
    "# y = list(df_final.high_salary.values)\n",
    "\n",
    "features = X.columns\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "model = RandomForestClassifier().fit(X_train,y_train)\n",
    "model.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.65648854961832059"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8232323232323232"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JOB</th>\n",
       "      <th>COMPANIES</th>\n",
       "      <th>SALARY</th>\n",
       "      <th>ACTUALLY_HIGH</th>\n",
       "      <th>PREDICTED_HIGH</th>\n",
       "      <th>PREDICTION_PROBA</th>\n",
       "      <th>CORRECT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SUPERVISORY HEALTH SCIENTIST</td>\n",
       "      <td>CENTERS FOR DISEASE CONTROL AND PREVENTION</td>\n",
       "      <td>143516.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SUPERVISORY HEALTH SCIENTIST</td>\n",
       "      <td>CENTERS FOR DISEASE CONTROL AND PREVENTION</td>\n",
       "      <td>143516.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>STATISTICIAN III - DIVISION OF PLANNING AND PR...</td>\n",
       "      <td>STATE OF SOUTH CAROLINA</td>\n",
       "      <td>56947.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 JOB  \\\n",
       "0                       SUPERVISORY HEALTH SCIENTIST   \n",
       "1                       SUPERVISORY HEALTH SCIENTIST   \n",
       "2  STATISTICIAN III - DIVISION OF PLANNING AND PR...   \n",
       "\n",
       "                                    COMPANIES    SALARY  ACTUALLY_HIGH  \\\n",
       "0  CENTERS FOR DISEASE CONTROL AND PREVENTION  143516.0              1   \n",
       "1  CENTERS FOR DISEASE CONTROL AND PREVENTION  143516.0              1   \n",
       "2                     STATE OF SOUTH CAROLINA   56947.5              0   \n",
       "\n",
       "   PREDICTED_HIGH  PREDICTION_PROBA CORRECT  \n",
       "0               0               0.2      No  \n",
       "1               1               0.8     Yes  \n",
       "2               0               0.5     Yes  "
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(sorted(zip(df_final.job,df_final.company,df_final.salary_clean,df_final.high_salary,predictions,predict_proba), key=lambda pair: pair[0], reverse=True),columns=['JOB','COMPANIES','SALARY','ACTUALLY_HIGH','PREDICTED_HIGH','PREDICTION_PROBA'])\n",
    "results['CORRECT']='No'\n",
    "results['CORRECT'][results.ACTUALLY_HIGH==results.PREDICTED_HIGH]='Yes'\n",
    "\n",
    "results.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n",
      "68\n",
      "0.433333333333\n"
     ]
    }
   ],
   "source": [
    "print len(results[results.CORRECT=='Yes'])\n",
    "print len(results[results.CORRECT=='No'])\n",
    "print len(results[results.CORRECT=='Yes']) / float(len(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Interesting that the score went up for the full dataset from the test set"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
