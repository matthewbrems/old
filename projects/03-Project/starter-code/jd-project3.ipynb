{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "69b9a648-bcc7-490d-9f9b-ea244d156bd6"
   },
   "source": [
    "# Web Scraping for Indeed.com & Predicting Salaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "34681254-c802-462f-829d-8894d0772d08"
   },
   "source": [
    "### Problem Statement:\n",
    "#### Can salaries for Data Scientist job listings be predicted as high or low, in comparison to the median salary posted, using various features of the posting? What will best predict whether it's higher or lower than the median?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions to grab the job title, company, location, salary, and brief description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis for Principal\n",
    "\n",
    "https://docs.google.com/document/d/16qF3YIrw4OdYrzfc9DpSkoTCKnOisrbD1_UR5Wr4BJw/edit?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## use various IDs, classes to identify the features\n",
    "## if they cannot be found, an error will be thrown,\n",
    "## and we will simply pass that attribute and move on\n",
    "\n",
    "def get_job(webpage):\n",
    "    tag = webpage.find('a', title=True, attrs={'data-tn-element':'jobTitle'})\n",
    "    try:\n",
    "        return tag['title']\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "def get_company(webpage):\n",
    "    tag = webpage.find('span', attrs={'class':'company'})\n",
    "    try:\n",
    "        return tag.text.strip('\\n')\n",
    "    except:\n",
    "        pass\n",
    "def get_location(webpage):\n",
    "    tag = webpage.find('span', attrs={'class':'location'})\n",
    "    try:\n",
    "        return tag.text\n",
    "    except:\n",
    "        pass    \n",
    "\n",
    "def get_salary(webpage):\n",
    "    try:\n",
    "        return webpage.find('table').tr.td.nobr.renderContents() ## for regular listings\n",
    "    except:\n",
    "        try:\n",
    "            return webpage.find('div').div.text ## for sponsored listings\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "def get_description(webpage):\n",
    "    description = webpage.find('span', attrs={'itemprop':\"description\"})\n",
    "    try:\n",
    "        return description.text.strip('\\n')\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "6e259594-1c52-436b-ab9e-527e071941c1"
   },
   "outputs": [],
   "source": [
    "###############\n",
    "###############\n",
    "### I chose to write a function to combine some of the steps\n",
    "### I also chose not to clean the salaries each time, but instead\n",
    "### will just clean them all at once, when I import the data from the csvs\n",
    "### pps I am not limiting my search to particular cities\n",
    "###############\n",
    "###############\n",
    "\n",
    "\n",
    "## first, define two functions that will be used in \n",
    "## the main scraping function: str_number_to_number, compile_files\n",
    "\n",
    "\n",
    "# given a string of a number with commas, convert to float\n",
    "def str_number_to_number(string):\n",
    "    import locale \n",
    "    string = string.strip('$')\n",
    "    locale.setlocale(locale.LC_ALL, 'en_US.UTF-8') #for american comma notation\n",
    "    # if european comma notation needed, change 2nd parameter to 'fr_FR'\n",
    "    num = locale.atof(string)\n",
    "    return float(num)\n",
    "\n",
    "\n",
    "## import the results that have been previously exported into df\n",
    "def compile_files():\n",
    "    import glob\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    indeed_csvs = '../indeed/'\n",
    "    files = glob.glob(indeed_csvs + '*.csv') # get a list of the csv files\n",
    "    indeed_final = pd.DataFrame(columns=['job','company','location','salary','description'])\n",
    "    for f in files: # read each csv file in\n",
    "        f = pd.read_csv(f, names=['job','company','location','salary','description'],low_memory=False)\n",
    "        indeed_final = indeed_final.append(f)\n",
    "    indeed_final.drop_duplicates(inplace=True)\n",
    "    return indeed_final\n",
    "\n",
    "\n",
    "######################################################\n",
    "######################################################\n",
    "################    SCRAPE TIME!!    #################\n",
    "######################################################\n",
    "######################################################\n",
    "\n",
    "\n",
    "def scrape_indeed():\n",
    "    \n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    import datetime\n",
    "    import time\n",
    "    import re\n",
    "    import numpy as np\n",
    " \n",
    "    \n",
    "    ## compile previously scraped results to see if there are new jobs to add\n",
    "    indeed = compile_files()    \n",
    "    base = len(indeed)\n",
    "    ## record start time to calculate elapsed time\n",
    "    start = datetime.datetime.now()\n",
    "    \n",
    "    print 'Start time: ',start.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    print 'Base file has ', base, ' records'\n",
    "\n",
    "    ## add '&fromage=last' to the url to get newly added jobs that might be skipped over otherwise\n",
    "    ## end the url at start= so we can dynamically flip through all pages of listings\n",
    "    url = \"http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&fromage=last&start=\"\n",
    "\n",
    "    ## x will indicate the number of the first listing on a particular page \n",
    "    ## each page lists 10 posts (and 5 sponsored posts)\n",
    "    x = 0\n",
    "    url_start = url+str(x)\n",
    "    page = requests.get(url_start).content\n",
    "    soup = BeautifulSoup(page,'lxml')\n",
    "    \n",
    "    print 'Page scraped & souped'\n",
    "    \n",
    "    ## take the full line that says 'Jobs x to y of z' and turn into a list\n",
    "    ## use to end the page loop -- function will stop looking \n",
    "    ## to the next page once it hits the last results\n",
    "    for results in soup.find('div', attrs={'id':'searchCount'}):\n",
    "        count = str(results).split()    \n",
    "        total = count[len(count)-1]          # set total to z, the total number o[f results\n",
    "        total = str_number_to_number(total)  # since there are commas if the number > 999, this function will deal with that and convert to int\n",
    "\n",
    "        \n",
    "    while x <= total-9:\n",
    "        ## go to new page of listings\n",
    "        url_new_page = url + str(x)\n",
    "        page = requests.get(url_new_page).content\n",
    "        soup = BeautifulSoup(page)\n",
    "        \n",
    "        ## record which number of listings we're at\n",
    "        ## for process notifications\n",
    "        for num_listings in  soup.find('div', attrs={'id':'searchCount'}) :\n",
    "            num_listings = num_listings.split()[3]\n",
    "        \n",
    "        main = soup.find('td',{'id':'resultsCol'})   # limit our searching to solely the results portion of the page\n",
    "        results = main.find_all('div', {'class': re.compile(\"result$\")}) # create a list consisting only of the 15 results\n",
    "\n",
    "        ## results has a list of the 10 listings on the page, plus the 5 sponsored\n",
    "        ## loop through each listing and get the job, company, location, salary, and decription info\n",
    "        for i in range(len(results)):\n",
    "            job = get_job(results[i])\n",
    "            company = get_company(results[i]) \n",
    "            location = get_location(results[i])\n",
    "            salary = get_salary(results[i])\n",
    "            description = get_description(results[i])\n",
    "\n",
    "            add_job = [job, company, location, salary, description]\n",
    "            indeed.append(add_job) ## add to main df\n",
    "\n",
    "        ## move to next page of results\n",
    "        x+=10\n",
    "        new = len(indeed) - base\n",
    "        elapsed = datetime.datetime.now() - start\n",
    "        remaining = total - x\n",
    "        est_pages = remaining/10\n",
    "        \n",
    "        ## print update after each page bc impatient\n",
    "        print 'Added ', new, ' jobs-- scraped ',num_listings,' of ', total, ' listings in ', elapsed, '; ', est_pages, ' pages remaining'\n",
    "        \n",
    "        time.sleep(0.5) ## wait a little to request the next page\n",
    "            \n",
    "    finish = datetime.datetime.now()\n",
    "    now = finish.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    print 'Finish time: ',now\n",
    "\n",
    "    elapsed = finish-start\n",
    "    print 'Elapsed: ',elapsed\n",
    "    indeed = pd.DataFrame(indeed)\n",
    "    \n",
    "    ## send results to csv file\n",
    "    indeed.to_csv('../indeed/'+now+'.csv',sep=',', encoding='utf-8',header=False,index=False)\n",
    "    return indeed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "04563b69-f7b6-466f-9d65-fc62c9ddee6a"
   },
   "source": [
    "## Predicting salaries using Random Forests + Another Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "243e949e-2742-40af-872e-fec475fd306c"
   },
   "source": [
    "#### Load in the the data of scraped salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "588f9845-6143-4bcc-bfd1-85d45b79303d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5662"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## YOUR CODE HERE\n",
    "\n",
    "indeed = compile_files()\n",
    "indeed.reset_index(drop=True)\n",
    "len(indeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python2.7/site-packages/pandas/core/generic.py:2773: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n",
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "//anaconda/lib/python2.7/site-packages/pandas/core/generic.py:4702: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n",
      "//anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2881: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "### CLEAN UP SALARIES\n",
    "###\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "## create a sub-df consisting only of jobs with annual salaries\n",
    "df=indeed[indeed.salary.notnull()&indeed.salary.str.contains('year')]\n",
    "df.salary = df.salary.astype(str)\n",
    "\n",
    "## turn the salary into a list so we can grab the high and low ends, then average\n",
    "df['salary_list'] = df.salary.str.split()\n",
    "\n",
    "mask = df.salary.str.contains('-')\n",
    "df['low_end'], df['high_end'], df['salary_clean'] = np.NaN, np.NaN, np.NaN\n",
    "df['low_end'][mask] = map(lambda x: x[0],df.salary_list.loc[mask])\n",
    "df['high_end'][mask] = map(lambda x: x[2],df.salary_list.loc[mask])\n",
    "\n",
    "df.low_end[df.high_end==1] = np.NaN\n",
    "df.high_end[df.high_end==1] = np.NaN\n",
    "\n",
    "df.salary_clean[df.salary.notnull()]= [x[0] for x in df.salary_list[df.salary_list.notnull()]]\n",
    "df.salary_clean[df.low_end.notnull()&df.high_end.notnull()] = np.NaN\n",
    "\n",
    "for col in ['salary_clean','low_end','high_end']:\n",
    "    df[col][df[col].notnull()] = [str_number_to_number(x) for x in df[col][df[col].notnull()]]\n",
    "\n",
    "# average out ranges\n",
    "df.salary_clean[df.salary_clean.isnull()] = (df.low_end + df.high_end) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "c7631f51-07f2-4c79-a093-3e9bc7849a48"
   },
   "source": [
    "#### We want to predict a binary variable - whether the salary was low or high. Compute the median salary and create a new binary variable that is true when the salary is high (above the median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "c20d2498-151c-44c3-a453-3a333c79a0ac"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "### BINARY TARGET FEATURE -- above (1) median or below (0) \n",
    "###\n",
    "\n",
    "\n",
    "df = df[df.salary_clean.notnull()]\n",
    "median_salary = np.median(df.salary_clean)\n",
    "df['high_salary'] = 1\n",
    "df['high_salary'][df.salary_clean <= median_salary] = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85000.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median_salary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "a7afb2c0-d41e-4779-8216-91cd8dd4473f"
   },
   "source": [
    "#### Thought experiment: What is the baseline accuracy for this model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.48965517,  0.48965517,  0.48965517])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###\n",
    "### LOGISTIC REGRESSION MODEL\n",
    "###\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "dummies = pd.get_dummies(df[['job','company','location']])\n",
    "\n",
    "X = pd.concat([dummies, df['salary_clean']], axis=1)\n",
    "y = df.high_salary\n",
    "\n",
    "cross_val_score(LogisticRegression(), X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "4fb29de2-5b98-474c-a4ad-5170b72b9aea"
   },
   "source": [
    "#### Create a Random Forest model to predict High/Low salary using Sklearn. Start by ONLY using the location as a feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###\n",
    "### CLEAN UP LOCATIONS -- parse to city, state\n",
    "###\n",
    "\n",
    "\n",
    "## remove areas in parentheses\n",
    "df.location = df.location.str.replace('\\((.*?)\\)','')\n",
    "df.location = df.location.str.strip()\n",
    "\n",
    "## remove zip codes\n",
    "df.location = df.location.str.replace(r'(\\d{5}(\\-\\d{4})?)$','')\n",
    "df.location = df.location.str.strip()\n",
    "\n",
    "## create feature with states\n",
    "df['state'] = df.location.str.findall('\\,\\s(\\D{2})$')\n",
    "\n",
    "## remove state from location\n",
    "df.location = df.location.str.replace('(\\,\\s\\D{2})$','')\n",
    "\n",
    "## take the states out of the list they were for some reason placed in\n",
    "df.state = df.state.astype(str)\n",
    "df.state = df.state.str.replace('(\\[)','')\n",
    "df.state = df.state.str.replace('(\\])','')\n",
    "df.state = df.state.str.replace('(\\')','')\n",
    "\n",
    "df.company = df.company.str.strip()\n",
    "df.company = df.company.str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###\n",
    "### DUM DUMS!!!!\n",
    "###\n",
    "\n",
    "\n",
    "X = pd.get_dummies(df[['location','state']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "ddbc6159-6854-4ca7-857f-bfecdaf6d9c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.ensemble.forest.RandomForestClassifier'> Score:\t0.687 ± 0.012\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "### RANDOM FOREST MODEL\n",
    "###\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, BaggingClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "def classify(Classifier, X, y, weight):\n",
    "    name = str(Classifier)\n",
    "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=41)\n",
    "    if weight != '':\n",
    "        dt = Classifier(class_weight=weight)\n",
    "    else:\n",
    "        dt = Classifier()\n",
    "    s = cross_val_score(dt, X, y, cv=cv, n_jobs=-1)\n",
    "    print \"{} Score:\\t{:0.3} ± {:0.3}\".format(name, s.mean().round(3), s.std().round(3))\n",
    "\n",
    "## output baseline score\n",
    "classify(RandomForestClassifier, X, y, 'balanced')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "0ef04f32-419c-4bf2-baf7-48201f03df89"
   },
   "source": [
    "#### Create a few new variables in your dataframe to represent interesting features of a job title.\n",
    "- For example, create a feature that represents whether 'Senior' is in the title \n",
    "- or whether 'Manager' is in the title. \n",
    "- Then build a new Random Forest with these features. Do they add any value? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "068dc1cf-7fd7-4f27-a1f1-7f0a5a221d29"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "### JOB TITLE VARIABLES\n",
    "###\n",
    "\n",
    "\n",
    "df.job = df.job.str.upper()\n",
    "df['analyst'] = 0\n",
    "df['analyst'][df.job.str.contains('ANALY')] = 1\n",
    "\n",
    "df['statistician'] = 0\n",
    "df['statistician'][df.job.str.contains('STATISTIC')] = 1\n",
    "\n",
    "df['machine_learning'] = 0\n",
    "df['machine_learning'][df.job.str.contains('MACHINE')] = 1\n",
    "\n",
    "df['research'] = 0\n",
    "df['research'][df.job.str.contains('RESEARCH')] = 1\n",
    "\n",
    "df['science'] = 0\n",
    "df['science'][df.job.str.contains('SCIEN')] = 1\n",
    "\n",
    "df['engineer'] = 0\n",
    "df['engineer'][df.job.str.contains('ENGIN')] = 1\n",
    "\n",
    "df['entry_level'] = 0\n",
    "df['entry_level'][df.job.str.contains('\\WI\\W')] = 1\n",
    "df['entry_level'][df.job.str.contains('\\WI$')] = 1\n",
    "df['entry_level'][df.job.str.contains('ENTRY_LEVEL')] = 1\n",
    "df['entry_level'][df.job.str.contains('1')] = 1\n",
    "\n",
    "df['mid_level'] = 0\n",
    "df['mid_level'][df.job.str.contains('MANAGER')] = 1\n",
    "df['mid_level'][df.job.str.contains('MID_LEVEL')] = 1\n",
    "df['mid_level'][df.job.str.contains('\\WII\\W')] = 1\n",
    "df['mid_level'][df.job.str.contains('\\WII$')] = 1\n",
    "df['mid_level'][df.job.str.contains('2')] = 1\n",
    "df['mid_level'][df.job.str.contains('ASSISTANT')] = 1\n",
    "\n",
    "df['senior_level'] = 0\n",
    "df['senior_level'][df.job.str.contains('\\WIII\\W')] = 1\n",
    "df['senior_level'][df.job.str.contains('\\WIII$')] = 1\n",
    "df['senior_level'][df.job.str.contains('3')] = 1\n",
    "df['senior_level'][df.job.str.contains('SR\\W')] = 1\n",
    "df['senior_level'][df.job.str.contains('SENIOR')] = 1\n",
    "df['senior_level'][df.job.str.contains('LEAD')] = 1\n",
    "df['senior_level'][df.job.str.contains('PRINCIPAL')] = 1\n",
    "df['senior_level'][df.job.str.contains('DIRECTOR')] = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "9c9274ef-c9f5-4d56-b286-ecc8709eff9f"
   },
   "source": [
    "#### Rebuild this model with the new variables\n",
    "- You can either create the dummy features manually or use the `dmatrix` function from `patsy`\n",
    "- Remember to scale the feature variables as well!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "b76f65cd-cd3a-4e91-af55-12880be7b057"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92439862542955331"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df.job.drop_duplicates(inplace=True)\n",
    "# df.reset_index(inplace=True)\n",
    "\n",
    "dummies = pd.get_dummies(df.location)\n",
    "df_final = pd.concat([dummies, df[['job','company','description','location','high_salary','salary_clean','analyst','engineer','machine_learning','mid_level','entry_level','senior_level']]], axis=1)\n",
    "\n",
    "df_final.job.drop_duplicates(inplace=True)\n",
    "df_final.reset_index(inplace=True)\n",
    "\n",
    "\n",
    "X = pd.concat([dummies, df[['analyst','engineer','machine_learning','mid_level','entry_level','senior_level']]], axis=1)\n",
    "features = X.columns\n",
    "y = list(df.high_salary.values)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "\n",
    "model = RandomForestClassifier().fit(X_train,y_train)\n",
    "model.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "9367beff-72ba-4768-a0ba-a50b335de61d"
   },
   "source": [
    "#### Use cross-validation in scikit-learn to evaluate the model above. \n",
    "- Evaluate the accuracy of the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "269b9e7c-60b5-4a06-8255-881d7395bc1b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.65979381,  0.65979381,  0.71134021])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(RandomForestClassifier(),X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "fead9b5b-7316-405d-87fd-e144dff0cbeb"
   },
   "source": [
    "#### Continue to incorporate other text features from the title or summary that you believe will predict the salary and examine their coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.091731</td>\n",
       "      <td>analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.039323</td>\n",
       "      <td>senior_level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.034947</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.034476</td>\n",
       "      <td>engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.032882</td>\n",
       "      <td>mid_level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.031616</td>\n",
       "      <td>machine_learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.022252</td>\n",
       "      <td>Reston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.019584</td>\n",
       "      <td>Washington</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.018887</td>\n",
       "      <td>Boston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.018317</td>\n",
       "      <td>Santa Clara</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.017860</td>\n",
       "      <td>Orange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.016634</td>\n",
       "      <td>San Jose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.016476</td>\n",
       "      <td>Chicago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.016045</td>\n",
       "      <td>Fort Meade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.015212</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.015063</td>\n",
       "      <td>Charlotte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.013219</td>\n",
       "      <td>Cleveland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.012540</td>\n",
       "      <td>entry_level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.012178</td>\n",
       "      <td>Queens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.012124</td>\n",
       "      <td>Bridgewater</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.012100</td>\n",
       "      <td>Tucson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.011979</td>\n",
       "      <td>College Park</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.011130</td>\n",
       "      <td>Iowa City</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.011116</td>\n",
       "      <td>San Francisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.011038</td>\n",
       "      <td>Silver Spring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.010925</td>\n",
       "      <td>Los Angeles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.010606</td>\n",
       "      <td>Tampa Bay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.010313</td>\n",
       "      <td>Pleasanton</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0                 1\n",
       "0   0.091731           analyst\n",
       "1   0.039323      senior_level\n",
       "2   0.034947          New York\n",
       "3   0.034476          engineer\n",
       "4   0.032882         mid_level\n",
       "5   0.031616  machine_learning\n",
       "6   0.022252            Reston\n",
       "7   0.019584        Washington\n",
       "8   0.018887            Boston\n",
       "9   0.018317       Santa Clara\n",
       "10  0.017860            Orange\n",
       "11  0.016634          San Jose\n",
       "12  0.016476           Chicago\n",
       "13  0.016045        Fort Meade\n",
       "14  0.015212     United States\n",
       "15  0.015063         Charlotte\n",
       "16  0.013219         Cleveland\n",
       "17  0.012540       entry_level\n",
       "18  0.012178            Queens\n",
       "19  0.012124       Bridgewater\n",
       "20  0.012100            Tucson\n",
       "21  0.011979      College Park\n",
       "22  0.011130         Iowa City\n",
       "23  0.011116     San Francisco\n",
       "24  0.011038     Silver Spring\n",
       "25  0.010925       Los Angeles\n",
       "26  0.010606         Tampa Bay\n",
       "27  0.010313        Pleasanton"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance = pd.DataFrame(sorted(zip(model.feature_importances_,features), key=lambda pair: pair[0], reverse=True))\n",
    "feature_importance = feature_importance[0:28]\n",
    "feature_importance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Keywords: research, analyst, statistician, engineer, machine learning\n",
    "## locations: LA, New York (generally)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_train)\n",
    "\n",
    "results = pd.DataFrame(sorted(zip(df_final.analyst, df_final.Reston, df_final['Los Angeles'], df_final.Queens, df_final.engineer, df_final['New York'],df_final.machine_learning,df_final.high_salary,predictions), key=lambda pair: pair[0], reverse=True),columns=['analyst', 'Reston', 'Los Angeles', 'Queens', 'engineer', 'New York','machine_learning','SALARY_HIGH','PREDICTION'])\n",
    "results['CORRECT']='Yes'\n",
    "results['CORRECT'][results.SALARY_HIGH!=results.PREDICTION]='No'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANALYST\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PREDICTION</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CORRECT</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>No</th>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yes</th>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         PREDICTION\n",
       "CORRECT            \n",
       "No               55\n",
       "Yes              57"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print 'ANALYST'\n",
    "results[['CORRECT','PREDICTION']][results.analyst==1].groupby(['CORRECT']).count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENGINEER\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PREDICTION</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CORRECT</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>No</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yes</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         PREDICTION\n",
       "CORRECT            \n",
       "No               20\n",
       "Yes              10"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print 'ENGINEER'\n",
    "results[['CORRECT','PREDICTION']][results.engineer==1].groupby(['CORRECT']).count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MACHINE LEARNING\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PREDICTION</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CORRECT</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>No</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yes</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         PREDICTION\n",
       "CORRECT            \n",
       "No               14\n",
       "Yes               4"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print 'MACHINE LEARNING'\n",
    "results[['CORRECT','PREDICTION']][results.machine_learning==1].groupby(['CORRECT']).count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "12d5edeb-a272-43a0-9977-d951f12fedfb"
   },
   "source": [
    "#### Take ~100 scraped entries with salaries. Convert them to use with your model and predict the salary - which entries have the highest predicted salaries?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85833333333333328"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "random_salaries = df_final.sample(n=120)\n",
    "# X_keep = df_final.features\n",
    "X_random = random_salaries[features]\n",
    "y_random = random_salaries.high_salary\n",
    "\n",
    "model.score(X_random,y_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(X_random)\n",
    "predict_proba = model.predict_proba(X_random)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JOB</th>\n",
       "      <th>COMPANIES</th>\n",
       "      <th>SALARY</th>\n",
       "      <th>ACTUALLY_HIGH</th>\n",
       "      <th>PREDICTED_HIGH</th>\n",
       "      <th>PREDICTION_PROBA</th>\n",
       "      <th>CORRECT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SUPERVISORY HEALTH SCIENTIST</td>\n",
       "      <td>CENTERS FOR DISEASE CONTROL AND PREVENTION</td>\n",
       "      <td>143516.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SUPERVISORY HEALTH SCIENTIST</td>\n",
       "      <td>CENTERS FOR DISEASE CONTROL AND PREVENTION</td>\n",
       "      <td>143516.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>STATISTICIAN III - DIVISION OF PLANNING AND PR...</td>\n",
       "      <td>STATE OF SOUTH CAROLINA</td>\n",
       "      <td>56947.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 JOB  \\\n",
       "0                       SUPERVISORY HEALTH SCIENTIST   \n",
       "1                       SUPERVISORY HEALTH SCIENTIST   \n",
       "2  STATISTICIAN III - DIVISION OF PLANNING AND PR...   \n",
       "\n",
       "                                    COMPANIES    SALARY  ACTUALLY_HIGH  \\\n",
       "0  CENTERS FOR DISEASE CONTROL AND PREVENTION  143516.0              1   \n",
       "1  CENTERS FOR DISEASE CONTROL AND PREVENTION  143516.0              1   \n",
       "2                     STATE OF SOUTH CAROLINA   56947.5              0   \n",
       "\n",
       "   PREDICTED_HIGH  PREDICTION_PROBA CORRECT  \n",
       "0               1               0.9     Yes  \n",
       "1               0               0.1      No  \n",
       "2               0               0.1     Yes  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(sorted(zip(df_final.job,df_final.company,df_final.salary_clean,df_final.high_salary,predictions,predict_proba), key=lambda pair: pair[0], reverse=True),columns=['JOB','COMPANIES','SALARY','ACTUALLY_HIGH','PREDICTED_HIGH','PREDICTION_PROBA'])\n",
    "results['CORRECT']='No'\n",
    "results['CORRECT'][results.ACTUALLY_HIGH==results.PREDICTED_HIGH]='Yes'\n",
    "\n",
    "results.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "56\n",
      "0.533333333333\n"
     ]
    }
   ],
   "source": [
    "print len(results[results.CORRECT=='Yes'])\n",
    "print len(results[results.CORRECT=='No'])\n",
    "print len(results[results.CORRECT=='Yes']) / float(len(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## So, model score ended up being pretty good,\n",
    "## but it looks like only half were predicted correctly -_____-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "3be94357-e551-4094-b784-2df039216d33"
   },
   "source": [
    "### BONUS "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "db045898-1d2d-4af2-8e79-437c4c7546b4"
   },
   "source": [
    "#### Bonus: Use Count Vectorizer from scikit-learn to create features from the text summaries. \n",
    "- Examine using count or binary features in the model\n",
    "- Re-evaluate your models using these. Does this improve the model performance? \n",
    "- What text features are the most valuable? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "4239e458-28bd-4675-8db3-c1d9c02b9854"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "df_final = df_final[df_final.description.notnull()]\n",
    "df_final.fillna(0,inplace=True)\n",
    "df_final.drop(df_final.index[177],inplace=True)\n",
    "\n",
    "cvec = CountVectorizer(stop_words='english')\n",
    "cvec.fit(df_final['description'])\n",
    "\n",
    "\n",
    "cvec_table  = pd.DataFrame(cvec.transform(df_final['description']).todense(),\n",
    "             columns=cvec.get_feature_names())\n",
    "cvec_table = cvec_table.transpose().transpose()\n",
    "cvec_table.reset_index(drop=True)\n",
    "cvec_table.drop([u'analyst', u'company', u'description', u'engineer', u'job'],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72727272727272729"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get species dummies and add to traps df\n",
    "dummies = pd.get_dummies(df_final, columns=['location'])\n",
    "dummies.drop\n",
    "\n",
    "# df = pd.concat([dummies, cvec_table,  df_final[['job','company','description','location','high_salary','salary_clean','analyst','statistician','engineer','machine_learning','research','mid_level','entry_level','senior_level']]], axis=1)\n",
    "# X = pd.concat([dummies, cvec_table, df_final[['analyst','statistician','engineer','machine_learning','research','mid_level','entry_level','senior_level']]], axis=1)\n",
    "# X = dummies.join(cvec_table)\n",
    "X = cvec_table\n",
    "# X.drop(X.index[177],inplace=True)\n",
    "# X.drop([u'analyst', u'company', u'description', u'engineer', u'job','high_salary','salary_clean'],inplace=True,axis=1)\n",
    "X.fillna(0,inplace=True)\n",
    "y = list(df_final.high_salary.values)\n",
    "features = X.columns\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "dtypes_x = pd.DataFrame(list(X_train.dtypes))\n",
    "cols_x = pd.DataFrame(list(X_train.columns),columns=['col'])\n",
    "t = dtypes_x.join(cols_x)\n",
    "# array([dtype('float64'), dtype('uint8'), dtype('O'), dtype('int64')], dtype=object)\n",
    "model = RandomForestClassifier().fit(X_train,y_train)\n",
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t[0] = t[0].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [0, col]\n",
       "Index: []"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[t[0]=='object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72727272727272729"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90719257540603249"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.025279</td>\n",
       "      <td>scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.017013</td>\n",
       "      <td>analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.015489</td>\n",
       "      <td>research</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.012740</td>\n",
       "      <td>machine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.012115</td>\n",
       "      <td>data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.011601</td>\n",
       "      <td>science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.011566</td>\n",
       "      <td>quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.010290</td>\n",
       "      <td>conduct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.010254</td>\n",
       "      <td>learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.009822</td>\n",
       "      <td>team</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.009608</td>\n",
       "      <td>collection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.008912</td>\n",
       "      <td>statistical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.008801</td>\n",
       "      <td>position</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.008652</td>\n",
       "      <td>modeling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.008360</td>\n",
       "      <td>analytical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.007857</td>\n",
       "      <td>analyze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.007844</td>\n",
       "      <td>sets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.007284</td>\n",
       "      <td>performing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.006970</td>\n",
       "      <td>management</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.006796</td>\n",
       "      <td>skills</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.006377</td>\n",
       "      <td>design</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.006313</td>\n",
       "      <td>work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.006222</td>\n",
       "      <td>policy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.006179</td>\n",
       "      <td>dashboards</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.005985</td>\n",
       "      <td>database</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.005881</td>\n",
       "      <td>requirement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.005872</td>\n",
       "      <td>problems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.005853</td>\n",
       "      <td>perform</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.005698</td>\n",
       "      <td>client</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.005545</td>\n",
       "      <td>include</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1646</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>vba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1647</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>vegetation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1648</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>vendor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1649</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>verifies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1650</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1651</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>visible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1652</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>visual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1653</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>visualize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1654</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>vital</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1655</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>vlookup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1656</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>voice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1657</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>vp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1658</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>wa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1659</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>want</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1660</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>warehouse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1661</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>warehouses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1662</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>warehousing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1663</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>washington</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1664</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>way</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1665</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>wayne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1666</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>weapon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1667</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>websites</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1668</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>western</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1669</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>willingness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1670</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>windows</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1671</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>worked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1672</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>works</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1673</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>worldwide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1674</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>written</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1675</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>wuermli</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1676 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      importance      feature\n",
       "0       0.025279    scientist\n",
       "1       0.017013     analysis\n",
       "2       0.015489     research\n",
       "3       0.012740      machine\n",
       "4       0.012115         data\n",
       "5       0.011601      science\n",
       "6       0.011566      quality\n",
       "7       0.010290      conduct\n",
       "8       0.010254     learning\n",
       "9       0.009822         team\n",
       "10      0.009608   collection\n",
       "11      0.008912  statistical\n",
       "12      0.008801     position\n",
       "13      0.008652     modeling\n",
       "14      0.008360   analytical\n",
       "15      0.007857      analyze\n",
       "16      0.007844         sets\n",
       "17      0.007284   performing\n",
       "18      0.006970   management\n",
       "19      0.006796       skills\n",
       "20      0.006377       design\n",
       "21      0.006313         work\n",
       "22      0.006222       policy\n",
       "23      0.006179   dashboards\n",
       "24      0.005985     database\n",
       "25      0.005881  requirement\n",
       "26      0.005872     problems\n",
       "27      0.005853      perform\n",
       "28      0.005698       client\n",
       "29      0.005545      include\n",
       "...          ...          ...\n",
       "1646    0.000000          vba\n",
       "1647    0.000000   vegetation\n",
       "1648    0.000000       vendor\n",
       "1649    0.000000     verifies\n",
       "1650    0.000000        video\n",
       "1651    0.000000      visible\n",
       "1652    0.000000       visual\n",
       "1653    0.000000    visualize\n",
       "1654    0.000000        vital\n",
       "1655    0.000000      vlookup\n",
       "1656    0.000000        voice\n",
       "1657    0.000000           vp\n",
       "1658    0.000000           wa\n",
       "1659    0.000000         want\n",
       "1660    0.000000    warehouse\n",
       "1661    0.000000   warehouses\n",
       "1662    0.000000  warehousing\n",
       "1663    0.000000   washington\n",
       "1664    0.000000          way\n",
       "1665    0.000000        wayne\n",
       "1666    0.000000       weapon\n",
       "1667    0.000000     websites\n",
       "1668    0.000000      western\n",
       "1669    0.000000  willingness\n",
       "1670    0.000000      windows\n",
       "1671    0.000000       worked\n",
       "1672    0.000000        works\n",
       "1673    0.000000    worldwide\n",
       "1674    0.000000      written\n",
       "1675    0.000000      wuermli\n",
       "\n",
       "[1676 rows x 2 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Create a df of the features and their scores, descending\n",
    "feature_importances = sorted(zip(model.feature_importances_,features), key=lambda pair: pair[0], reverse=True)\n",
    "feature_importances = pd.DataFrame(feature_importances,columns=['importance','feature'])\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91666666666666663"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## I don't want to use all of the features, just the important ones\n",
    "## even though most have low scores ... \n",
    "features = list(feature_importances.feature[0:36])\n",
    "\n",
    "X = X[features]\n",
    "# y = list(df_final.high_salary.values)\n",
    "\n",
    "features = X.columns\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "model = RandomForestClassifier().fit(X_train,y_train)\n",
    "model.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68531468531468531"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83990719257540603"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JOB</th>\n",
       "      <th>COMPANIES</th>\n",
       "      <th>SALARY</th>\n",
       "      <th>ACTUALLY_HIGH</th>\n",
       "      <th>PREDICTED_HIGH</th>\n",
       "      <th>PREDICTION_PROBA</th>\n",
       "      <th>CORRECT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SUPERVISORY HEALTH SCIENTIST</td>\n",
       "      <td>CENTERS FOR DISEASE CONTROL AND PREVENTION</td>\n",
       "      <td>143516.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SUPERVISORY HEALTH SCIENTIST</td>\n",
       "      <td>CENTERS FOR DISEASE CONTROL AND PREVENTION</td>\n",
       "      <td>143516.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>STATISTICIAN III - DIVISION OF PLANNING AND PR...</td>\n",
       "      <td>STATE OF SOUTH CAROLINA</td>\n",
       "      <td>56947.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 JOB  \\\n",
       "0                       SUPERVISORY HEALTH SCIENTIST   \n",
       "1                       SUPERVISORY HEALTH SCIENTIST   \n",
       "2  STATISTICIAN III - DIVISION OF PLANNING AND PR...   \n",
       "\n",
       "                                    COMPANIES    SALARY  ACTUALLY_HIGH  \\\n",
       "0  CENTERS FOR DISEASE CONTROL AND PREVENTION  143516.0              1   \n",
       "1  CENTERS FOR DISEASE CONTROL AND PREVENTION  143516.0              1   \n",
       "2                     STATE OF SOUTH CAROLINA   56947.5              0   \n",
       "\n",
       "   PREDICTED_HIGH  PREDICTION_PROBA CORRECT  \n",
       "0               1               0.9     Yes  \n",
       "1               0               0.1      No  \n",
       "2               0               0.1     Yes  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(sorted(zip(df_final.job,df_final.company,df_final.salary_clean,df_final.high_salary,predictions,predict_proba), key=lambda pair: pair[0], reverse=True),columns=['JOB','COMPANIES','SALARY','ACTUALLY_HIGH','PREDICTED_HIGH','PREDICTION_PROBA'])\n",
    "results['CORRECT']='No'\n",
    "results['CORRECT'][results.ACTUALLY_HIGH==results.PREDICTED_HIGH]='Yes'\n",
    "\n",
    "results.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "56\n",
      "0.533333333333\n"
     ]
    }
   ],
   "source": [
    "print len(results[results.CORRECT=='Yes'])\n",
    "print len(results[results.CORRECT=='No'])\n",
    "print len(results[results.CORRECT=='Yes']) / float(len(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Interesting that the score went up for the full dataset from the test set"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
